"""
Case Study v2 Routes
PU Learning Workbench - Advanced experimental workbench routes

=== DATABASE DATETIME FORMAT RULE ===
All datetime fields in SQLite database MUST use the following format:
- Format: 'YYYY-MM-DD HH:MM:SS' (e.g., '2025-08-25 23:20:34')
- Generated by: datetime.now().strftime('%Y-%m-%d %H:%M:%S')
- Compatible with: Prisma ORM, SQLite DATETIME type
- DO NOT USE: ISO format with 'T' separator or timezone info
==========================================
"""

from fastapi import APIRouter, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks, Depends
from typing import List, Dict, Any, Optional
import asyncio
import json
import uuid
import logging
from datetime import datetime
import sys
import os

# Configure logging
logger = logging.getLogger(__name__)

# Create router
case_study_v2_router = APIRouter(prefix="/api/v2", tags=["Case Study v2"])

# Global variables for services (initialized later)
db_manager = None
candidate_generator = None
model_trainer = None
model_evaluator = None
websocket_manager = None

def get_model_evaluator():
    """Dependency injection for model evaluator"""
    if model_evaluator is None:
        raise HTTPException(status_code=503, detail="Case Study v2 services not initialized")
    return model_evaluator

def get_current_datetime():
    """
    Returns current datetime in Taiwan timezone (UTC+8) in SQLite-compatible format
    Format: 'YYYY-MM-DD HH:MM:SS' (e.g., '2025-08-25 23:20:34')
    """
    from datetime import datetime
    import pytz
    taiwan_tz = pytz.timezone('Asia/Taipei')
    taiwan_time = datetime.now(taiwan_tz)
    return taiwan_time.strftime('%Y-%m-%d %H:%M:%S')

def update_analysis_dataset_positive_labels(cursor, dataset_id):
    """
    更新指定 AnalysisDataset 的 positiveLabels 計數

    Args:
        cursor: 數據庫游標
        dataset_id: 數據集ID

    Returns:
        int: 新的 positiveLabels 數量，失敗時返回 None
    """
    try:
        # 統計該數據集中確認的正標籤數量
        cursor.execute("""
            SELECT COUNT(*)
            FROM anomaly_event
            WHERE dataset_id = ? AND status = 'CONFIRMED_POSITIVE'
        """, (dataset_id,))

        confirmed_positive_count = cursor.fetchone()[0]

        # 統計 AnalysisReadyData 中的正標籤數量
        cursor.execute("""
            SELECT COUNT(*)
            FROM analysis_ready_data
            WHERE dataset_id = ? AND is_positive_label = 1
        """, (dataset_id,))

        analysis_positive_count = cursor.fetchone()[0]

        # 取兩者的最大值
        new_positive_labels = max(confirmed_positive_count, analysis_positive_count)

        # 更新 AnalysisDataset
        cursor.execute("""
            UPDATE analysis_datasets
            SET positive_labels = ?
            WHERE id = ?
        """, (new_positive_labels, dataset_id))

        logger.info(f"Updated AnalysisDataset {dataset_id} positiveLabels: {analysis_positive_count} (analysis) + {confirmed_positive_count} (confirmed) = {new_positive_labels}")
        return new_positive_labels

    except Exception as e:
        logger.error(f"Failed to update AnalysisDataset positiveLabels for dataset {dataset_id}: {e}")
        return None

def _import_case_study_v2_modules():
    """Dynamically import case-study-v2 modules"""
    try:
        # Import the services from the new location
        from services.case_study_v2 import (
            DatabaseManager,
            CandidateGenerator,
            ModelTrainer,
            ModelEvaluator,
            WebSocketManager
        )
        logger.info("Successfully imported case study v2 modules")
        return {
            'DatabaseManager': DatabaseManager,
            'CandidateGenerator': CandidateGenerator,
            'ModelTrainer': ModelTrainer,
            'ModelEvaluator': ModelEvaluator,
            'WebSocketManager': WebSocketManager
        }
    except ImportError as e:
        logger.error(f"Failed to import case-study-v2 modules: {e}")
        return None

async def init_case_study_v2():
    """Initialize Case Study v2 services"""
    global db_manager, candidate_generator, model_trainer, model_evaluator, websocket_manager

    try:
        # Import modules
        modules = _import_case_study_v2_modules()
        if not modules:
            logger.warning("Case Study v2 modules not available, using fallback responses")
            return False

        # Initialize database manager
        db_manager = modules['DatabaseManager']()
        await db_manager.connect()

        # Initialize services
        candidate_generator = modules['CandidateGenerator'](db_manager)
        model_trainer = modules['ModelTrainer'](db_manager)
        model_evaluator = modules['ModelEvaluator'](db_manager)
        websocket_manager = modules['WebSocketManager']()

        logger.info("Case Study v2 services initialized successfully")
        return True

    except Exception as e:
        logger.error(f"Failed to initialize Case Study v2 services: {e}")
        # Still allow fallback functionality
        logger.warning("Continuing with fallback implementation")
        return False

async def cleanup_case_study_v2():
    """Cleanup Case Study v2 services"""
    global db_manager
    if db_manager:
        try:
            await db_manager.disconnect()
            logger.info("Case Study v2 services cleanup complete")
        except Exception as e:
            logger.error(f"Error during Case Study v2 cleanup: {e}")

# ========== API Routes ==========

@case_study_v2_router.post("/experiment-runs")
async def create_experiment_run(request: dict):
    """Creates a new ExperimentRun and initiates candidate generation"""
    try:
        # Use direct SQLite connection
        import sqlite3
        import uuid
        from datetime import datetime

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # Generate new ID
        experiment_id = str(uuid.uuid4())
        current_time = get_current_datetime()  # Use unified datetime format

        # Create experiment run
        cursor.execute('''
            INSERT INTO experiment_run (
                id, name, description, filtering_parameters, status,
                candidate_count, positive_label_count, negative_label_count,
                created_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            experiment_id,
            request.get('name', 'Unnamed Experiment'),
            request.get('description'),
            json.dumps(request.get('filtering_parameters', {})),
            'CONFIGURING',
            0, 0, 0,
            current_time,
            current_time
        ))

        conn.commit()
        conn.close()

        return {
            'id': experiment_id,
            'name': request.get('name', 'Unnamed Experiment'),
            'description': request.get('description'),
            'status': 'CONFIGURING',
            'candidateCount': 0,
            'createdAt': current_time
        }

    except Exception as e:
        logger.error(f"Error creating experiment run: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@case_study_v2_router.post("/generate-candidates")
async def generate_candidates(request: dict):
    """Generates anomaly candidates based on filter parameters"""
    try:
        # 解析請求參數
        filter_params = request.get("filter_params", {})
        save_labels = request.get("save_labels", False)  # 新增參數：是否保存為實際標籤
        existing_experiment_run_id = request.get("experiment_run_id")  # 現有的實驗ID

        logger.info(f"[GENERATE_CANDIDATES] ===== 開始處理請求 =====")
        logger.info(f"[GENERATE_CANDIDATES] 完整請求參數: {request}")
        logger.info(f"[GENERATE_CANDIDATES] save_labels 參數: {save_labels}")
        logger.info(f"[GENERATE_CANDIDATES] existing_experiment_run_id: {existing_experiment_run_id}")
        logger.info(f"[GENERATE_CANDIDATES] filter_params: {filter_params}")

        # 提取過濾參數
        selected_dataset_ids = filter_params.get("selectedDatasetIds", [])
        buildings = filter_params.get("buildings", [])
        floors = filter_params.get("floors", [])
        rooms = filter_params.get("rooms", [])
        occupant_types = filter_params.get("occupantTypes", [])

        # 異常檢測參數
        z_score_threshold = filter_params.get("zScoreThreshold", 2.5)
        spike_threshold = filter_params.get("spikeThreshold", 200)
        min_event_duration = filter_params.get("minEventDuration", 30)

        # 時間範圍
        start_date = filter_params.get("startDate", "")
        start_time = filter_params.get("startTime", "")
        end_date = filter_params.get("endDate", "")
        end_time = filter_params.get("endTime", "")

        import sqlite3
        import json
        import numpy as np

        # 連接到主資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 建立基礎查詢條件
        where_conditions = []
        params = []

        # 資料集過濾
        if selected_dataset_ids:
            placeholders = ','.join(['?' for _ in selected_dataset_ids])
            where_conditions.append(f"id IN ({placeholders})")
            params.extend(selected_dataset_ids)

        # 建築物過濾
        if buildings:
            placeholders = ','.join(['?' for _ in buildings])
            where_conditions.append(f"building IN ({placeholders})")
            params.extend(buildings)

        # 樓層過濾
        if floors:
            placeholders = ','.join(['?' for _ in floors])
            where_conditions.append(f"floor IN ({placeholders})")
            params.extend(floors)

        # 房間過濾
        if rooms:
            placeholders = ','.join(['?' for _ in rooms])
            where_conditions.append(f"room IN ({placeholders})")
            params.extend(rooms)

        # 佔用者類型過濾
        if occupant_types:
            placeholders = ','.join(['?' for _ in occupant_types])
            where_conditions.append(f"occupant_type IN ({placeholders})")
            params.extend(occupant_types)

        # 構建查詢
        base_query = "SELECT * FROM analysis_datasets"
        if where_conditions:
            base_query += " WHERE " + " AND ".join(where_conditions)

        cursor.execute(base_query, params)
        filtered_datasets = cursor.fetchall()

        # 使用真實數據進行異常檢測來計算候選數量
        total_candidates = 0
        anomaly_events_to_create = []  # 用於保存異常事件數據

        # 總數據池統計
        total_data_pool_size = 0
        total_positive_labels = 0
        total_negative_labels = 0

        if filtered_datasets:
            import numpy as np

            # 獲取數據集列名
            columns = [desc[0] for desc in cursor.description]

            # 首先計算總數據池統計
            for dataset_row in filtered_datasets:
                dataset = dict(zip(columns, dataset_row))
                dataset_id = dataset['id']

                # 查詢該數據集的記錄數和已知正樣本數
                cursor.execute('''
                    SELECT COUNT(*) as total_records,
                           SUM(CASE WHEN is_positive_label = 1 THEN 1 ELSE 0 END) as positive_count
                    FROM analysis_ready_data
                    WHERE dataset_id = ?
                ''', (dataset_id,))

                stats_result = cursor.fetchone()
                if stats_result:
                    dataset_total_records = stats_result[0] or 0
                    dataset_positive_count = stats_result[1] or 0
                    dataset_negative_count = dataset_total_records - dataset_positive_count

                    total_data_pool_size += dataset_total_records
                    total_positive_labels += dataset_positive_count
                    total_negative_labels += dataset_negative_count

                    logger.info(f"[GENERATE_CANDIDATES] 數據集 {dataset['name']}: {dataset_total_records} 總記錄, {dataset_positive_count} 正樣本, {dataset_negative_count} 負樣本")

            logger.info(f"[GENERATE_CANDIDATES] 總數據池統計: 總大小={total_data_pool_size}, 正樣本={total_positive_labels}, 負樣本={total_negative_labels}")

            for dataset_row in filtered_datasets:
                dataset = dict(zip(columns, dataset_row))
                dataset_id = dataset['id']

                logger.info(f"[GENERATE_CANDIDATES] 分析數據集: {dataset['name']}")

                # 查詢該數據集的實際電力數據
                cursor.execute('''
                    SELECT timestamp, wattage_total, wattage_110v, wattage_220v
                    FROM analysis_ready_data
                    WHERE dataset_id = ?
                    ORDER BY timestamp
                ''', (dataset_id,))

                power_data = cursor.fetchall()

                if not power_data:
                    logger.warning(f"[GENERATE_CANDIDATES] 數據集 {dataset_id} 沒有實際數據")
                    continue

                # 轉換為 numpy arrays 進行分析
                timestamps = [row[0] for row in power_data]
                wattage_total = np.array([row[1] for row in power_data])
                wattage_110v = np.array([row[2] for row in power_data])
                wattage_220v = np.array([row[3] for row in power_data])

                # 建立異常標記數組，避免重複計算
                anomaly_mask = np.zeros(len(wattage_total), dtype=bool)

                logger.info(f"[GENERATE_CANDIDATES] 數據集總數據點: {len(wattage_total)}")

                # 1. Z-score 異常檢測
                z_anomaly_count = 0
                if len(wattage_total) > 1:
                    # 計算總功率的 Z-score
                    mean_power = np.mean(wattage_total)
                    std_power = np.std(wattage_total)

                    if std_power > 0:
                        z_scores = np.abs((wattage_total - mean_power) / std_power)
                        z_anomaly_mask = z_scores > z_score_threshold
                        z_anomaly_count = int(np.sum(z_anomaly_mask))  # 確保是標準 Python int

                        # 添加到總異常標記
                        anomaly_mask |= z_anomaly_mask

                        logger.info(f"[GENERATE_CANDIDATES] Z-score 異常 (閾值 {z_score_threshold}): {z_anomaly_count}")

                # 2. 功率峰值檢測（使用相對閾值）
                # 計算相對於平均功率的峰值閾值
                mean_power = np.mean(wattage_total)
                # spike_threshold 是百分比，轉換為絕對閾值
                absolute_spike_threshold = mean_power * (1 + spike_threshold / 100.0)

                spike_anomaly_mask = wattage_total > absolute_spike_threshold
                spike_anomaly_count = int(np.sum(spike_anomaly_mask))  # 確保是標準 Python int

                # 添加到總異常標記
                anomaly_mask |= spike_anomaly_mask

                logger.info(f"[GENERATE_CANDIDATES] 功率峰值 (相對閾值 {spike_threshold}%, 絕對閾值 {absolute_spike_threshold:.1f}W): {spike_anomaly_count}")

                # 3. 連續性檢測 - 檢測數據跳躍
                jump_anomaly_count = 0
                if len(wattage_total) > 1:
                    power_diff = np.abs(np.diff(wattage_total))
                    diff_threshold = np.mean(wattage_total) * 0.5  # 50% 功率變化閾值

                    # 為 diff 創建與原數組長度相同的 mask（最後一個元素設為 False）
                    jump_anomaly_mask = np.zeros(len(wattage_total), dtype=bool)
                    jump_anomaly_mask[:-1] = power_diff > diff_threshold

                    jump_anomaly_count = int(np.sum(jump_anomaly_mask))  # 確保是標準 Python int

                    # 添加到總異常標記
                    anomaly_mask |= jump_anomaly_mask

                    logger.info(f"[GENERATE_CANDIDATES] 功率跳躍異常: {jump_anomaly_count}")

                # 計算聯集後的總異常數量
                total_anomalies = int(np.sum(anomaly_mask))  # 確保是標準 Python int

                # 4. 最小事件持續時間過濾
                # 將連續的異常點聚合成事件
                # 簡化實現：根據最小持續時間要求來減少候選數量

                # 持續時間過濾：較長的持續時間要求應該產生較少的候選
                # 假設每分鐘一個數據點，基準為 30 分鐘
                duration_factor = min(1.0, 30.0 / max(1, min_event_duration))
                dataset_candidates = int(total_anomalies * duration_factor)

                # 確保候選數量不超過原始數據點數量的合理比例（最多 10%）
                max_reasonable_candidates = max(1, int(len(wattage_total) * 0.1))
                dataset_candidates = min(dataset_candidates, max_reasonable_candidates)

                total_candidates += max(0, dataset_candidates)

                # 如果需要保存標籤，準備異常事件數據
                if save_labels and dataset_candidates > 0:
                    logger.info(f"[GENERATE_CANDIDATES] 準備創建異常事件，save_labels={save_labels}, dataset_candidates={dataset_candidates}")
                    # 找到異常的時間點
                    anomaly_indices = np.where(anomaly_mask)[0]
                    logger.info(f"[GENERATE_CANDIDATES] 找到 {len(anomaly_indices)} 個異常索引")

                    # 根據 duration_factor 選擇部分異常點作為候選事件
                    if len(anomaly_indices) > dataset_candidates:
                        # 隨機選擇或按重要性選擇
                        selected_indices = np.random.choice(
                            anomaly_indices,
                            size=dataset_candidates,
                            replace=False
                        )
                    else:
                        selected_indices = anomaly_indices

                    logger.info(f"[GENERATE_CANDIDATES] 選擇了 {len(selected_indices)} 個異常點作為事件")

                    # 為每個選中的異常點創建事件數據
                    for idx in selected_indices:
                        # 構建時間窗口的 JSON 格式數據
                        window_start_idx = max(0, idx - 5)
                        window_end_idx = min(len(timestamps) - 1, idx + 5)
                        data_window_json = json.dumps({
                            "startTime": timestamps[window_start_idx],
                            "endTime": timestamps[window_end_idx],
                            "centerIndex": int(idx),  # 確保是標準 Python int
                            "wattageTotal": float(wattage_total[idx]),
                            "wattage110v": float(wattage_110v[idx]),
                            "wattage220v": float(wattage_220v[idx])
                        })

                        # Generate descriptive name for anomaly event
                        # Format: BuildingRoom_metric_>thresholdValue
                        building = dataset.get('building', 'Unknown')
                        room = dataset.get('room', '000')
                        current_wattage = float(wattage_total[idx])

                        # Extract building letter and room number for compact format
                        # e.g., "Building A" -> "A", "203" -> "203"
                        building_code = building.split()[-1] if building else "X"
                        room_code = room.replace(" ", "").replace("號房", "").replace("Room", "")

                        # Determine which threshold was exceeded by checking each condition
                        # Re-check conditions for this specific index
                        mean_power = np.mean(wattage_total)
                        std_power = np.std(wattage_total)

                        is_z_anomaly = False
                        is_spike_anomaly = False

                        if std_power > 0:
                            z_score = abs((wattage_total[idx] - mean_power) / std_power)
                            is_z_anomaly = z_score > z_score_threshold

                        absolute_spike_threshold = mean_power * (1 + spike_threshold / 100.0)
                        is_spike_anomaly = wattage_total[idx] > absolute_spike_threshold

                        # Generate appropriate name based on detection type
                        if is_z_anomaly:
                            event_name = f"{building_code}{room_code}_wattage_total_zscore>{z_score_threshold}σ_{current_wattage:.0f}W"
                        elif is_spike_anomaly:
                            event_name = f"{building_code}{room_code}_wattage_total_spike>{spike_threshold}%_{current_wattage:.0f}W"
                        else:
                            event_name = f"{building_code}{room_code}_wattage_total_anomaly_{current_wattage:.0f}W"

                        anomaly_events_to_create.append({
                            'dataset_id': dataset_id,  # 使用數據集 ID 而不是 meter_id
                            'name': event_name,
                            'line': 'L1',  # 預設為 L1，後續可根據需要調整
                            'event_timestamp': timestamps[idx],
                            'detection_rule': f"Z-score:{z_score_threshold},Spike:{spike_threshold}%,Duration:{min_event_duration}min",
                            'score': float(0.8),  # 預設信心分數
                            'data_window': data_window_json
                        })

                    logger.info(f"[GENERATE_CANDIDATES] 總共準備創建 {len(anomaly_events_to_create)} 個異常事件")

                logger.info(f"[GENERATE_CANDIDATES] Z-score: {z_anomaly_count}, 峰值: {spike_anomaly_count}, 跳躍: {jump_anomaly_count}")
                logger.info(f"[GENERATE_CANDIDATES] 聯集後總異常: {total_anomalies}, 持續時間調整後: {dataset_candidates}")
                logger.info(f"[GENERATE_CANDIDATES] 數據集 {dataset['name']} 最終候選數: {dataset_candidates}")

        logger.info(f"[GENERATE_CANDIDATES] 總候選數: {total_candidates}")

        # 如果只是預覽模式，不創建實驗運行記錄，直接返回結果
        if not save_labels:
            conn.commit()
            conn.close()

            logger.info(f"[GENERATE_CANDIDATES] 預覽模式完成，總候選數: {total_candidates}")
            return {
                "success": True,
                "candidate_count": int(total_candidates),  # 確保是標準 Python int
                "status": "preview",
                "total_data_pool_size": int(total_data_pool_size),
                "positive_label_count": int(total_positive_labels),
                "negative_label_count": int(total_negative_labels),
                "data_pool_summary": {
                    "total_datasets": int(len(filtered_datasets)),
                    "total_pool_size": int(total_data_pool_size),
                    "positive_labels": int(total_positive_labels),
                    "negative_labels": int(total_negative_labels),
                    "positive_ratio": round(total_positive_labels / total_data_pool_size * 100, 2) if total_data_pool_size > 0 else 0
                },
                "message": f"Preview completed. Found {int(total_candidates)} potential candidates from total data pool of {int(total_data_pool_size)} records."
            }

        # 只有在 save_labels=True 時才創建或更新實驗運行記錄
        from datetime import datetime

        # 如果提供了現有的實驗ID，使用它；否則創建新的
        if existing_experiment_run_id:
            experiment_run_id = existing_experiment_run_id
            logger.info(f"[GENERATE_CANDIDATES] 使用現有實驗ID: {experiment_run_id}")
        else:
            experiment_run_id = str(uuid.uuid4())
            logger.info(f"[GENERATE_CANDIDATES] 創建新實驗ID: {experiment_run_id}")

        current_timestamp = get_current_datetime()  # Use unified datetime format

        # 構建實驗名稱 - 從 current_timestamp 提取日期時間部分
        timestamp_for_name = current_timestamp[:16]  # 取 'YYYY-MM-DD HH:MM' 部分
        experiment_name = f"Candidate Generation - {timestamp_for_name}"
        experiment_name += " [LABELING]"  # 標籤模式總是標記為 LABELING
        if buildings:
            experiment_name += f" - Buildings: {', '.join(buildings[:2])}{'...' if len(buildings) > 2 else ''}"

        # 標籤模式的狀態總是 LABELING
        status = "LABELING"

        # 如果使用現有實驗ID，先嘗試更新記錄；如果找不到，則創建新記錄
        experiment_created_or_updated = False

        if existing_experiment_run_id:
            # 先檢查實驗記錄是否存在
            cursor.execute('SELECT id FROM experiment_run WHERE id = ?', (experiment_run_id,))
            existing_record = cursor.fetchone()

            if existing_record:
                # 更新現有實驗記錄
                logger.info(f"[GENERATE_CANDIDATES] 準備更新現有實驗記錄 ID: {experiment_run_id}")
                logger.info(f"[GENERATE_CANDIDATES] 更新資料: status={status}, candidate_count={total_candidates}")

                cursor.execute('''
                    UPDATE experiment_run
                    SET description = ?, filtering_parameters = ?, status = ?,
                        candidate_count = ?, total_data_pool_size = ?,
                        positive_label_count = ?, negative_label_count = ?, updated_at = ?
                    WHERE id = ?
                ''', (
                    f"Generated {total_candidates} anomaly candidates using filter criteria",
                    json.dumps(filter_params, sort_keys=True),
                    status,
                    total_candidates,
                    total_data_pool_size,
                    total_positive_labels,
                    total_negative_labels,
                    current_timestamp,
                    experiment_run_id
                ))

                # 檢查更新是否成功
                rows_affected = cursor.rowcount
                logger.info(f"[GENERATE_CANDIDATES] 更新完成，影響的行數: {rows_affected}")

                if rows_affected > 0:
                    logger.info(f"[GENERATE_CANDIDATES] 成功更新現有實驗記錄: {experiment_run_id}")
                    experiment_created_or_updated = True
                else:
                    logger.warning(f"[GENERATE_CANDIDATES] 更新失敗，將改為創建新記錄")
            else:
                logger.warning(f"[GENERATE_CANDIDATES] 找不到 ID 為 {experiment_run_id} 的實驗記錄，將創建新記錄")

        # 如果是全新創建，或者更新失敗，則插入新實驗記錄
        if not experiment_created_or_updated:
            # 如果原本的ID不存在，生成新的ID
            if existing_experiment_run_id and not existing_record:
                logger.info(f"[GENERATE_CANDIDATES] 原ID {experiment_run_id} 不存在，生成新ID")
                experiment_run_id = str(uuid.uuid4())
                logger.info(f"[GENERATE_CANDIDATES] 新生成的實驗ID: {experiment_run_id}")

            logger.info(f"[GENERATE_CANDIDATES] 準備創建新實驗記錄 ID: {experiment_run_id}")
            logger.info(f"[GENERATE_CANDIDATES] 新記錄資料: status={status}, candidate_count={total_candidates}")

            cursor.execute('''
                INSERT INTO experiment_run
                (id, name, description, filtering_parameters, status, candidate_count,
                 total_data_pool_size, positive_label_count, negative_label_count, created_at, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                experiment_run_id,
                experiment_name,
                f"Generated {total_candidates} anomaly candidates using filter criteria",
                json.dumps(filter_params, sort_keys=True),
                status,
                total_candidates,
                total_data_pool_size,
                total_positive_labels,
                total_negative_labels,
                current_timestamp,
                current_timestamp
            ))
            logger.info(f"[GENERATE_CANDIDATES] 成功創建新實驗記錄: {experiment_run_id}")
            experiment_created_or_updated = True

        # 創建實際的 anomaly_event 記錄
        anomaly_events_created = 0
        if anomaly_events_to_create and experiment_created_or_updated:
            logger.info(f"[GENERATE_CANDIDATES] 開始創建 {len(anomaly_events_to_create)} 個異常事件記錄")

            # 清理舊的異常事件記錄
            if existing_experiment_run_id and existing_record:
                # 如果是更新現有實驗，只清理該實驗的異常事件
                cursor.execute('''
                    DELETE FROM anomaly_event
                    WHERE experiment_run_id = ?
                ''', (experiment_run_id,))
                deleted_events_count = cursor.rowcount
                logger.info(f"[GENERATE_CANDIDATES] 清理現有實驗的舊異常事件: 刪除了 {deleted_events_count} 個記錄")
            else:
                # 如果是創建新實驗，清理具有相同參數的舊LABELING實驗
                filter_params_json = json.dumps(filter_params, sort_keys=True)
                cursor.execute('''
                    SELECT id, name FROM experiment_run
                    WHERE filtering_parameters = ? AND status = 'LABELING' AND id != ?
                    ORDER BY created_at DESC
                ''', (filter_params_json, experiment_run_id))

                existing_labeling_runs = cursor.fetchall()

                if existing_labeling_runs:
                    logger.info(f"[GENERATE_CANDIDATES] 找到 {len(existing_labeling_runs)} 個具有相同參數的舊LABELING實驗")
                    for run in existing_labeling_runs:
                        logger.info(f"[GENERATE_CANDIDATES] 將清理實驗: {run[0]} - {run[1]}")

                    run_ids_to_clean = [run[0] for run in existing_labeling_runs]
                    placeholders = ','.join(['?' for _ in run_ids_to_clean])

                    # 先刪除異常事件
                    delete_events_query = f'''
                        DELETE FROM anomaly_event
                        WHERE experiment_run_id IN ({placeholders})
                    '''
                    cursor.execute(delete_events_query, run_ids_to_clean)
                    deleted_events_count = cursor.rowcount

                    # 再刪除舊的實驗運行記錄
                    delete_runs_query = f'''
                        DELETE FROM experiment_run
                        WHERE id IN ({placeholders})
                    '''
                    cursor.execute(delete_runs_query, run_ids_to_clean)
                    deleted_runs_count = cursor.rowcount

                    logger.info(f"[GENERATE_CANDIDATES] 清理舊資料: 刪除了 {deleted_events_count} 個異常事件和 {deleted_runs_count} 個實驗運行記錄")
                else:
                    logger.info(f"[GENERATE_CANDIDATES] 沒有找到需要清理的舊實驗記錄")

            for event_data in anomaly_events_to_create:
                anomaly_event_id = str(uuid.uuid4())
                event_id = f"AUTO_{anomaly_event_id[:8]}"
                cursor.execute('''
                    INSERT INTO anomaly_event
                    (id, event_id, name, dataset_id, line, event_timestamp, detection_rule, score,
                     data_window, status, experiment_run_id, created_at, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    anomaly_event_id,
                    event_id,
                    event_data['name'],
                    event_data['dataset_id'],
                    event_data['line'],
                    event_data['event_timestamp'],
                    event_data['detection_rule'],
                    event_data['score'],
                    event_data['data_window'],
                    'UNREVIEWED',
                    experiment_run_id,
                    current_timestamp,
                    current_timestamp
                ))
                anomaly_events_created += 1

            logger.info(f"[GENERATE_CANDIDATES] 創建了 {anomaly_events_created} 個異常事件記錄")
        elif not experiment_created_or_updated:
            logger.error(f"[GENERATE_CANDIDATES] 實驗記錄創建/更新失敗，跳過異常事件創建")

        conn.commit()

        # 只有在實驗記錄成功創建/更新時才進行驗證
        if experiment_created_or_updated:
            # 驗證實驗記錄是否正確更新
            cursor.execute('SELECT id, name, status, candidate_count, updated_at FROM experiment_run WHERE id = ?', (experiment_run_id,))
            verification_result = cursor.fetchone()

            if verification_result:
                logger.info(f"[GENERATE_CANDIDATES] 資料庫驗證 - 實驗記錄 {experiment_run_id}:")
                logger.info(f"  - ID: {verification_result[0]}")
                logger.info(f"  - Name: {verification_result[1]}")
                logger.info(f"  - Status: {verification_result[2]}")
                logger.info(f"  - Candidate Count: {verification_result[3]}")
                logger.info(f"  - Updated At: {verification_result[4]}")
            else:
                logger.error(f"[GENERATE_CANDIDATES] 錯誤：無法在資料庫中找到實驗記錄 {experiment_run_id}")
        else:
            logger.error(f"[GENERATE_CANDIDATES] 實驗記錄處理失敗，跳過驗證")

        conn.close()

        if experiment_created_or_updated:
            logger.info(f"Generated {total_candidates} candidates and created {anomaly_events_created} anomaly events for experiment {experiment_run_id}")

            # 確保所有值都是 JSON 可序列化的
            import json
            response = {
                "success": True,
                "experiment_run_id": str(experiment_run_id),
                "candidate_count": int(total_candidates),  # 確保是標準 Python int
                "anomaly_events_created": int(anomaly_events_created),  # 確保是標準 Python int
                "status": "LABELING",
                "filtered_datasets_count": int(len(filtered_datasets)),
                "total_data_pool_size": int(total_data_pool_size),
                "positive_label_count": int(total_positive_labels),
                "negative_label_count": int(total_negative_labels),
                "filter_summary": {
                    "buildings": list(buildings) if buildings else [],
                    "floors": list(floors) if floors else [],
                    "rooms": list(rooms) if rooms else [],
                    "occupant_types": list(occupant_types) if occupant_types else [],
                    "z_score_threshold": float(z_score_threshold),  # 確保是標準 Python float
                    "spike_threshold": int(spike_threshold)  # 確保是標準 Python int
                },
                "data_pool_summary": {
                    "total_datasets": int(len(filtered_datasets)),
                    "total_pool_size": int(total_data_pool_size),
                    "positive_labels": int(total_positive_labels),
                    "negative_labels": int(total_negative_labels),
                    "positive_ratio": round(total_positive_labels / total_data_pool_size * 100, 2) if total_data_pool_size > 0 else 0
                },
                "message": f"Successfully generated {int(total_candidates)} anomaly candidates from total data pool of {int(total_data_pool_size)} records ({int(total_positive_labels)} positive, {int(total_negative_labels)} negative)"
            }

            # 測試 JSON 序列化
            try:
                json.dumps(response)
            except TypeError as e:
                logger.error(f"JSON serialization error: {e}")
                # 返回一個簡化的響應
                response = {
                    "success": True,
                    "experiment_run_id": str(experiment_run_id),
                    "candidate_count": int(total_candidates),
                    "anomaly_events_created": int(anomaly_events_created),
                    "status": "LABELING",
                    "message": "Successfully generated candidates"
                }
        else:
            logger.error(f"Failed to create or update experiment run")
            response = {
                "success": False,
                "error": "Failed to create or update experiment run",
                "message": "Experiment run could not be created or updated"
            }

        return response

    except Exception as e:
        logger.error(f"Error generating candidates: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@case_study_v2_router.get("/experiment-runs")
async def get_experiment_runs():
    """Retrieves a list of all ExperimentRun records"""
    try:
        # Use direct SQLite connection
        import sqlite3

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # Query all experiment runs
        cursor.execute('''
            SELECT id, name, description, filtering_parameters, status,
                   candidate_count, positive_label_count, negative_label_count,
                   created_at, updated_at, candidate_stats, total_data_pool_size
            FROM experiment_run
            ORDER BY created_at DESC
            LIMIT 100
        ''')

        rows = cursor.fetchall()
        conn.close()

        # Format response
        result = []
        for row in rows:
            # Parse JSON fields
            filtering_parameters = {}
            candidate_stats = {}

            try:
                if row[3]:  # filtering_parameters
                    filtering_parameters = json.loads(row[3])
            except json.JSONDecodeError:
                pass

            try:
                if row[10]:  # candidate_stats
                    candidate_stats = json.loads(row[10])
            except json.JSONDecodeError:
                pass

            result.append({
                'id': row[0],
                'name': row[1],
                'description': row[2],
                'filteringParameters': filtering_parameters,
                'status': row[4],
                'candidateCount': row[5],
                'positiveLabelCount': row[6],
                'negativeLabelCount': row[7],
                'createdAt': row[8],
                'updatedAt': row[9],
                'candidateStats': candidate_stats,
                'anomalyEvents': [],
                'trainedModels': [],
                'totalDataPoolSize': row[11]
            })

        return result

    except Exception as e:
        logger.error(f"Error fetching experiment runs: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
@case_study_v2_router.get("/experiment-runs/{run_id}")
async def get_experiment_run(run_id: str):
    """Retrieves a specific ExperimentRun by ID"""
    try:
        # 直接使用主資料庫讀取特定的 experiment_run
        import sqlite3
        import json

        # 連接到主資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 查詢特定實驗運行
        cursor.execute('''
            SELECT id, name, description, filtering_parameters, status,
                   candidate_count, positive_label_count, negative_label_count,
                   created_at, updated_at, candidate_stats, total_data_pool_size
            FROM experiment_run
            WHERE id = ?
        ''', (run_id,))

        row = cursor.fetchone()

        if not row:
            raise HTTPException(status_code=404, detail="Experiment run not found")

        # 解析 JSON 欄位
        filtering_parameters = {}
        candidate_stats = {}

        try:
            if row[3]:  # filtering_parameters
                filtering_parameters = json.loads(row[3])
        except json.JSONDecodeError:
            pass

        try:
            if row[10]:  # candidate_stats
                candidate_stats = json.loads(row[10])
        except json.JSONDecodeError:
            pass

        # 轉換時間戳記
        from datetime import datetime
        created_at = None
        updated_at = None

        if row[8]:  # created_at
            try:
                created_at = datetime.fromtimestamp(row[8] / 1000).isoformat() + "Z"
            except:
                created_at = str(row[8])

        if row[9]:  # updated_at
            try:
                # 如果是 ISO 字符串格式，直接使用
                if isinstance(row[9], str) and ('T' in row[9] or 'Z' in row[9]):
                    updated_at = row[9]
                else:
                    # 如果是時間戳，則轉換
                    updated_at = datetime.fromtimestamp(float(row[9]) / 1000).isoformat() + "Z"
            except:
                updated_at = str(row[9])

        result = {
            "id": row[0],
            "name": row[1],
            "description": row[2],
            "filtering_parameters": filtering_parameters,
            "status": row[4] or "UNKNOWN",
            "candidate_count": row[5],
            "positive_label_count": row[6],
            "negative_label_count": row[7],
            "created_at": created_at,
            "updated_at": updated_at,
            "candidate_stats": candidate_stats,
            "total_data_pool_size": row[11]
        }

        conn.close()

        logger.info(f"Successfully retrieved experiment run: {run_id}")
        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching experiment run {run_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@case_study_v2_router.delete("/experiment-runs/{run_id}")
async def delete_experiment_run(run_id: str):
    """Delete an experiment run and all associated data"""
    try:
        import sqlite3

        # 連接到主資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 檢查實驗是否存在
        cursor.execute('SELECT id FROM experiment_run WHERE id = ?', (run_id,))
        if not cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=404, detail="Experiment run not found")

        # 由於 SQLite 支援級聯刪除，我們需要手動刪除相關資料
        # 按照依賴順序刪除：ModelPrediction -> EvaluationRun -> TrainedModel -> EventLabelLink -> AnomalyEvent -> ExperimentRun

        # 1. 刪除 ModelPrediction (透過 EvaluationRun 關聯)
        cursor.execute('''
            DELETE FROM model_predictions
            WHERE evaluation_run_id IN (
                SELECT er.id FROM evaluation_runs er
                JOIN trained_models tm ON er.trained_model_id = tm.id
                WHERE tm.experiment_run_id = ?
            )
        ''', (run_id,))

        # 2. 刪除 EvaluationRun (透過 TrainedModel 關聯)
        cursor.execute('''
            DELETE FROM evaluation_runs
            WHERE trained_model_id IN (
                SELECT id FROM trained_models WHERE experiment_run_id = ?
            )
        ''', (run_id,))

        # 3. 刪除 TrainedModel
        cursor.execute('DELETE FROM trained_models WHERE experiment_run_id = ?', (run_id,))

        # 4. 刪除 EventLabelLink (透過 AnomalyEvent 關聯)
        cursor.execute('''
            DELETE FROM event_label_link
            WHERE event_id IN (
                SELECT id FROM anomaly_event WHERE experiment_run_id = ?
            )
        ''', (run_id,))

        # 5. 刪除 AnomalyEvent
        cursor.execute('DELETE FROM anomaly_event WHERE experiment_run_id = ?', (run_id,))

        # 6. 最後刪除 ExperimentRun
        cursor.execute('DELETE FROM experiment_run WHERE id = ?', (run_id,))

        # 提交所有變更
        conn.commit()
        conn.close()

        logger.info(f"Successfully deleted experiment run: {run_id}")
        return {"success": True, "message": "Experiment run and all associated data deleted successfully"}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error deleting experiment run {run_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to delete experiment run: {str(e)}")

@case_study_v2_router.get("/experiment-runs/{run_id}/candidates")
async def get_experiment_candidates(run_id: str):
    """Fetches all AnomalyEvent candidates for a given ExperimentRun"""
    try:
        # 直接使用主資料庫讀取異常事件候選
        import sqlite3
        import json

        # 連接到主資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 查詢指定實驗運行的異常事件
        cursor.execute('''
            SELECT ae.id, ae.event_id, ae.dataset_id, ae.line, ae.event_timestamp, ae.detection_rule, ae.score,
                   ae.data_window, ae.status, ae.reviewer_id, ae.review_timestamp, ae.justification_notes,
                   ae.created_at, ae.updated_at, ae.experiment_run_id, ae.name
            FROM anomaly_event ae
            WHERE ae.experiment_run_id = ?
            ORDER BY ae.event_timestamp DESC
        ''', (run_id,))

        rows = cursor.fetchall()

        # 轉換為字典格式
        result = []
        for row in rows:
            # 解析 JSON 欄位
            data_window = {}
            try:
                if row[7]:  # data_window (調整索引)
                    data_window = json.loads(row[7])
            except json.JSONDecodeError:
                pass

            # 轉換時間戳記
            from datetime import datetime
            event_timestamp = None
            review_timestamp = None
            created_at = None
            updated_at = None

            if row[4]:  # event_timestamp (調整索引)
                try:
                    if isinstance(row[4], str):
                        event_timestamp = row[4]
                    else:
                        event_timestamp = datetime.fromtimestamp(row[4] / 1000).isoformat() + "Z"
                except:
                    event_timestamp = str(row[4])

            if row[10]:  # review_timestamp (調整索引)
                try:
                    if isinstance(row[10], str):
                        review_timestamp = row[10]
                    else:
                        review_timestamp = datetime.fromtimestamp(row[10] / 1000).isoformat() + "Z"
                except:
                    review_timestamp = str(row[10])

            if row[12]:  # created_at (調整索引)
                try:
                    if isinstance(row[12], str):
                        created_at = row[12]
                    else:
                        created_at = datetime.fromtimestamp(row[12] / 1000).isoformat() + "Z"
                except:
                    created_at = str(row[12])

            if row[13]:  # updated_at (調整索引)
                try:
                    if isinstance(row[13], str):
                        updated_at = row[13]
                    else:
                        updated_at = datetime.fromtimestamp(row[13] / 1000).isoformat() + "Z"
                except:
                    updated_at = str(row[13])

            result.append({
                "id": row[0],
                "event_id": row[1],
                "dataset_id": row[2],
                "line": row[3],
                "event_timestamp": event_timestamp,
                "detection_rule": row[5],
                "score": row[6],
                "data_window": data_window,
                "status": row[8] or "PENDING",
                "reviewer_id": row[9],
                "review_timestamp": review_timestamp,
                "justification_notes": row[11],
                "created_at": created_at,
                "updated_at": updated_at,
                "experiment_run_id": row[14],
                "dataset": {
                    "name": row[15] if row[15] else "Unknown Event"
                }
            })

        conn.close()

        logger.info(f"Successfully retrieved {len(result)} candidates for experiment {run_id}")
        return result

    except Exception as e:
        logger.error(f"Error fetching candidates for experiment {run_id}: {str(e)}")

        # 回傳空陣列作為後援
        logger.warning(f"Falling back to empty array for experiment {run_id}")
        return []

@case_study_v2_router.post("/anomaly-events/{event_id}/label")
async def label_anomaly_event(event_id: str, request: dict):
    """Submits a label for an AnomalyEvent"""
    try:
        # 直接使用主資料庫更新異常事件標籤
        import sqlite3

        # 解析請求參數
        status = request.get("status")
        reviewer_id = request.get("reviewer_id")
        justification_notes = request.get("justification_notes", "")

        if not status or not reviewer_id:
            raise HTTPException(status_code=400, detail="status and reviewer_id are required")

        # 連接到主資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 檢查異常事件是否存在
        cursor.execute('SELECT id FROM anomaly_event WHERE id = ?', (event_id,))
        if not cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=404, detail="Anomaly event not found")

        # 更新異常事件狀態
        current_timestamp = get_current_datetime()  # Use unified datetime format

        cursor.execute('''
            UPDATE anomaly_event
            SET status = ?, reviewer_id = ?, justification_notes = ?,
                review_timestamp = ?, updated_at = ?
            WHERE id = ?
        ''', (status, reviewer_id, justification_notes, current_timestamp, current_timestamp, event_id))

        if cursor.rowcount == 0:
            conn.close()
            raise HTTPException(status_code=404, detail="Anomaly event not found")

        conn.commit()
        conn.close()

        logger.info(f"Successfully labeled anomaly event {event_id} with status {status}")
        return {
            "success": True,
            "message": "Event labeled successfully",
            "event_id": event_id,
            "status": status,
            "reviewer_id": reviewer_id
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error labeling event {event_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

# ========== Stage 2: Expert Labeling API Routes ==========

@case_study_v2_router.get("/anomaly-events")
async def get_anomaly_events(
    experiment_run_id: str = None,
    status: str = None,
    limit: int = 100,
    offset: int = 0,
    count_only: bool = False
):
    """
    獲取異常事件列表，支援過濾和分頁
    主要用於 Stage 2 的事件審核介面
    支援 count_only=true 來只返回總數
    """
    try:
        import sqlite3

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 建立查詢條件
        where_conditions = []
        params = []

        if experiment_run_id:
            where_conditions.append("experiment_run_id = ?")
            params.append(experiment_run_id)

        if status:
            where_conditions.append("status = ?")
            params.append(status)

        # 如果只需要計數
        if count_only:
            count_query = "SELECT COUNT(*) FROM anomaly_event ae"
            if where_conditions:
                count_query += " WHERE " + " AND ".join(where_conditions)

            cursor.execute(count_query, params)
            total_count = cursor.fetchone()[0]
            conn.close()

            return {"total": total_count}

        # 構建查詢 - 直接讀取 anomaly_event 的 name 欄位
        query = """
            SELECT ae.id, ae.event_id, ae.dataset_id, ae.line, ae.event_timestamp, ae.detection_rule,
                   ae.score, ae.status, ae.data_window, ae.reviewer_id, ae.review_timestamp,
                   ae.justification_notes, ae.experiment_run_id, ae.created_at, ae.name
            FROM anomaly_event ae
        """

        if where_conditions:
            query += " WHERE " + " AND ".join(where_conditions)

        query += " ORDER BY score DESC, event_timestamp DESC LIMIT ? OFFSET ?"
        params.extend([limit, offset])

        cursor.execute(query, params)
        events = cursor.fetchall()

        # 轉換為字典格式
        columns = [desc[0] for desc in cursor.description]
        result = []

        for event_row in events:
            event_dict = dict(zip(columns, event_row))

            # 添加 name 信息到結果中 (直接使用 anomaly_event 的 name)
            if 'name' in event_dict:
                event_dict['dataset'] = {
                    'name': event_dict['name'] if event_dict['name'] else "Unknown Event"
                }

            # 解析 data_window 格式 (可能是字符串或 JSON)
            if event_dict['data_window']:
                try:
                    # 嘗試解析為 JSON
                    event_dict['data_window'] = json.loads(event_dict['data_window'])
                except (json.JSONDecodeError, TypeError):
                    # 如果不是 JSON，可能是時間範圍字符串格式 [start - end]
                    window_str = event_dict['data_window']
                    if window_str.startswith('[') and ' - ' in window_str:
                        # 解析 "[2025-07-27T10:13:00.000Z - 2025-07-27T14:03:00.000Z]" 格式
                        times = window_str.strip('[]').split(' - ')
                        if len(times) == 2:
                            event_dict['data_window'] = {
                                'startTime': times[0].strip(),
                                'endTime': times[1].strip(),
                                'duration': window_str
                            }
                        else:
                            event_dict['data_window'] = {'raw': window_str}
                    else:
                        event_dict['data_window'] = {'raw': window_str}

            # 添加 metadata 欄位用於前端兼容
            event_dict['metadata'] = {}

            result.append(event_dict)

        conn.close()

        logger.info(f"Retrieved {len(result)} anomaly events for experiment {experiment_run_id}, status: {status}")
        return result

    except Exception as e:
        logger.error(f"Error fetching anomaly events: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch anomaly events: {str(e)}")

@case_study_v2_router.post("/anomaly-events/bulk-review")
async def bulk_review_anomaly_events(request: dict):
    """
    批量審核異常事件
    支持將多個事件一次性標記為正異常或正常
    """
    try:
        import sqlite3

        # 解析請求參數
        event_ids = request.get("event_ids", [])
        status = request.get("status")
        reviewer_id = request.get("reviewer_id")
        justification_notes = request.get("justification_notes", "")

        # 驗證必需參數
        if not event_ids or not status or not reviewer_id:
            raise HTTPException(status_code=400, detail="event_ids, status and reviewer_id are required")

        if not isinstance(event_ids, list) or len(event_ids) == 0:
            raise HTTPException(status_code=400, detail="event_ids must be a non-empty list")

        # 驗證狀態值
        valid_statuses = ["CONFIRMED_POSITIVE", "REJECTED_NORMAL"]
        if status not in valid_statuses:
            raise HTTPException(status_code=400, detail=f"Invalid status. Must be one of: {valid_statuses}")

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)

        try:
            # 開始事務
            conn.execute("BEGIN TRANSACTION")
            cursor = conn.cursor()

            current_timestamp = get_current_datetime()
            updated_events = []
            experiment_run_ids = set()

            # 處理每個事件
            for event_id in event_ids:
                # 1. 查詢並驗證異常事件
                cursor.execute("""
                    SELECT id, dataset_id, event_timestamp, status, experiment_run_id
                    FROM anomaly_event
                    WHERE id = ?
                """, (event_id,))

                event_row = cursor.fetchone()
                if not event_row:
                    logger.warning(f"Anomaly event {event_id} not found, skipping")
                    continue

                current_status = event_row[3]
                if current_status != "UNREVIEWED":
                    logger.warning(f"Event {event_id} has already been reviewed, skipping")
                    continue

                event_dataset_id = event_row[1]
                event_timestamp = event_row[2]
                experiment_run_id = event_row[4]
                experiment_run_ids.add(experiment_run_id)

                # 2. 更新異常事件狀態
                cursor.execute("""
                    UPDATE anomaly_event
                    SET status = ?, reviewer_id = ?, justification_notes = ?,
                        review_timestamp = ?, updated_at = ?
                    WHERE id = ?
                """, (status, reviewer_id, justification_notes, current_timestamp, current_timestamp, event_id))

                # 3. 如果確認為異常，更新相關的 AnalysisReadyData
                if status == "CONFIRMED_POSITIVE":
                    cursor.execute("""
                        UPDATE analysis_ready_data
                        SET is_positive_label = 1, source_anomaly_event_id = ?
                        WHERE dataset_id = ? AND timestamp = ?
                    """, (event_id, event_dataset_id, event_timestamp))

                    # 如果沒有找到完全匹配的記錄，嘗試時間範圍匹配
                    if cursor.rowcount == 0:
                        from datetime import datetime, timedelta

                        try:
                            event_dt = datetime.fromisoformat(event_timestamp.replace('Z', '+00:00'))
                            start_window = (event_dt - timedelta(minutes=5)).strftime('%Y-%m-%d %H:%M:%S')
                            end_window = (event_dt + timedelta(minutes=5)).strftime('%Y-%m-%d %H:%M:%S')

                            cursor.execute("""
                                SELECT id
                                FROM analysis_ready_data
                                WHERE dataset_id = ?
                                AND timestamp BETWEEN ? AND ?
                                ORDER BY ABS(julianday(timestamp) - julianday(?)) ASC
                                LIMIT 1
                            """, (event_dataset_id, start_window, end_window, event_timestamp))

                            matching_record = cursor.fetchone()
                            if matching_record:
                                cursor.execute("""
                                    UPDATE analysis_ready_data
                                    SET is_positive_label = 1, source_anomaly_event_id = ?
                                    WHERE id = ?
                                """, (event_id, matching_record[0]))

                        except Exception as dt_error:
                            logger.error(f"Error processing timestamp for event {event_id}: {dt_error}")

                # 3.5. 更新 AnalysisDataset 的 positiveLabels
                new_positive_count = update_analysis_dataset_positive_labels(cursor, event_dataset_id)
                if new_positive_count is not None:
                    logger.info(f"Updated AnalysisDataset {event_dataset_id} positiveLabels to {new_positive_count}")

                updated_events.append(event_id)

            # 4. 更新所有相關實驗運行的統計數據
            for experiment_run_id in experiment_run_ids:
                cursor.execute("""
                    SELECT
                        COUNT(*) as total_candidates,
                        SUM(CASE WHEN status = 'CONFIRMED_POSITIVE' THEN 1 ELSE 0 END) as positive_count,
                        SUM(CASE WHEN status = 'REJECTED_NORMAL' THEN 1 ELSE 0 END) as negative_count
                    FROM anomaly_event
                    WHERE experiment_run_id = ?
                """, (experiment_run_id,))

                stats_row = cursor.fetchone()
                if stats_row:
                    total_candidates, positive_count, negative_count = stats_row

                    # 計算總數據池大小（基於實驗中使用的數據集）
                    cursor.execute("""
                        SELECT SUM(ard_counts.total_records) as total_data_pool_size
                        FROM (
                            SELECT DISTINCT dataset_id, COUNT(*) as total_records
                            FROM analysis_ready_data ard
                            WHERE ard.dataset_id IN (
                                SELECT DISTINCT ae.dataset_id
                                FROM anomaly_event ae
                                WHERE ae.experiment_run_id = ?
                            )
                            GROUP BY dataset_id
                        ) ard_counts
                    """, (experiment_run_id,))

                    total_data_pool_result = cursor.fetchone()
                    total_data_pool_size = total_data_pool_result[0] if total_data_pool_result and total_data_pool_result[0] else 0

                    # 計算總數據池中的正標籤數（基於 AnalysisReadyData 中的 is_positive_label）
                    cursor.execute("""
                        SELECT SUM(positive_counts.positive_labels) as total_positive_labels
                        FROM (
                            SELECT dataset_id, COUNT(*) as positive_labels
                            FROM analysis_ready_data ard
                            WHERE ard.dataset_id IN (
                                SELECT DISTINCT ae.dataset_id
                                FROM anomaly_event ae
                                WHERE ae.experiment_run_id = ?
                            ) AND ard.is_positive_label = 1
                            GROUP BY dataset_id
                        ) positive_counts
                    """, (experiment_run_id,))

                    total_positive_result = cursor.fetchone()
                    total_positive_in_pool = total_positive_result[0] if total_positive_result and total_positive_result[0] else 0

                    # 計算總數據池中的負標籤數
                    total_negative_in_pool = total_data_pool_size - total_positive_in_pool

                    cursor.execute("""
                        UPDATE experiment_run
                        SET candidate_count = ?,
                            positive_label_count = ?,
                            negative_label_count = ?,
                            total_data_pool_size = ?,
                            updated_at = ?
                        WHERE id = ?
                    """, (total_candidates, total_positive_in_pool, total_negative_in_pool, total_data_pool_size, current_timestamp, experiment_run_id))

                    logger.info(f"Bulk update: Updated experiment {experiment_run_id} with pool stats: total_pool={total_data_pool_size}, positive={total_positive_in_pool}, negative={total_negative_in_pool}, candidates={total_candidates}")

            # 4.5. 更新所有相關 AnalysisDataset 的 positiveLabels
            affected_datasets = set()
            for event_id in updated_events:
                cursor.execute("SELECT dataset_id FROM anomaly_event WHERE id = ?", (event_id,))
                dataset_result = cursor.fetchone()
                if dataset_result:
                    affected_datasets.add(dataset_result[0])

            for dataset_id in affected_datasets:
                new_positive_count = update_analysis_dataset_positive_labels(cursor, dataset_id)
                if new_positive_count is not None:
                    logger.info(f"Bulk update: AnalysisDataset {dataset_id} positiveLabels updated to {new_positive_count}")

            # 提交事務
            conn.commit()

            logger.info(f"Successfully bulk reviewed {len(updated_events)} events with status {status} by reviewer {reviewer_id}")

            return {
                "success": True,
                "message": f"Successfully reviewed {len(updated_events)} events",
                "updated_events": updated_events,
                "total_requested": len(event_ids),
                "total_updated": len(updated_events),
                "status": status,
                "reviewer_id": reviewer_id,
                "review_timestamp": current_timestamp
            }

        except Exception as e:
            # 回滾事務
            conn.rollback()
            raise e

        finally:
            conn.close()

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error bulk reviewing events: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to bulk review events: {str(e)}")

@case_study_v2_router.post("/anomaly-events/bulk-review-by-experiment")
async def bulk_review_by_experiment(request: dict):
    """
    按實驗批量審核所有未標記的異常事件
    支持將特定實驗的所有 UNREVIEWED 事件一次性標記為正異常或正常
    """
    try:
        import sqlite3

        # 解析請求參數
        experiment_run_id = request.get("experiment_run_id")
        status = request.get("status")
        reviewer_id = request.get("reviewer_id")
        justification_notes = request.get("justification_notes", "")

        # 驗證必需參數
        if not experiment_run_id or not status or not reviewer_id:
            raise HTTPException(status_code=400, detail="experiment_run_id, status and reviewer_id are required")

        # 驗證狀態值
        valid_statuses = ["CONFIRMED_POSITIVE", "REJECTED_NORMAL"]
        if status not in valid_statuses:
            raise HTTPException(status_code=400, detail=f"Invalid status. Must be one of: {valid_statuses}")

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)

        try:
            # 開始事務
            conn.execute("BEGIN TRANSACTION")
            cursor = conn.cursor()

            current_timestamp = get_current_datetime()

            # 1. 獲取所有未審核的事件
            cursor.execute("""
                SELECT id, event_id, dataset_id, event_timestamp
                FROM anomaly_event
                WHERE experiment_run_id = ? AND status = 'UNREVIEWED'
            """, (experiment_run_id,))

            unreviewed_events = cursor.fetchall()
            event_count = len(unreviewed_events)

            if event_count == 0:
                conn.close()
                return {
                    "success": True,
                    "message": "No unreviewed events found",
                    "updated_events": [],
                    "total_updated": 0,
                    "status": status,
                    "reviewer_id": reviewer_id,
                    "review_timestamp": current_timestamp
                }

            # 2. 更新所有未審核事件的狀態
            placeholders = ','.join(['?' for _ in range(event_count)])
            event_ids = [event[0] for event in unreviewed_events]

            cursor.execute(f"""
                UPDATE anomaly_event
                SET status = ?, reviewer_id = ?, review_timestamp = ?, justification_notes = ?
                WHERE id IN ({placeholders})
            """, [status, reviewer_id, current_timestamp, justification_notes] + event_ids)

            # 3. 更新 analysis_ready_data 中的標籤
            if status == "CONFIRMED_POSITIVE":
                for event_id, event_event_id, event_dataset_id, event_timestamp in unreviewed_events:
                    cursor.execute("""
                        UPDATE analysis_ready_data
                        SET is_positive_label = 1, source_anomaly_event_id = ?
                        WHERE dataset_id = ? AND timestamp = ?
                    """, (event_id, event_dataset_id, event_timestamp))

                    # 如果沒有找到完全匹配的記錄，嘗試時間範圍匹配
                    if cursor.rowcount == 0:
                        from datetime import datetime, timedelta

                        try:
                            event_dt = datetime.fromisoformat(event_timestamp.replace('Z', '+00:00'))
                            start_window = (event_dt - timedelta(minutes=5)).strftime('%Y-%m-%d %H:%M:%S')
                            end_window = (event_dt + timedelta(minutes=5)).strftime('%Y-%m-%d %H:%M:%S')

                            cursor.execute("""
                                SELECT id
                                FROM analysis_ready_data
                                WHERE dataset_id = ?
                                AND timestamp BETWEEN ? AND ?
                                ORDER BY ABS(julianday(timestamp) - julianday(?)) ASC
                                LIMIT 1
                            """, (event_dataset_id, start_window, end_window, event_timestamp))

                            matching_record = cursor.fetchone()
                            if matching_record:
                                cursor.execute("""
                                    UPDATE analysis_ready_data
                                    SET is_positive_label = 1, source_anomaly_event_id = ?
                                    WHERE id = ?
                                """, (event_id, matching_record[0]))

                        except Exception as dt_error:
                            logger.error(f"Error processing timestamp for event {event_id}: {dt_error}")

            # 4. 更新實驗運行的統計數據
            cursor.execute("""
                SELECT
                    COUNT(*) as total_candidates,
                    SUM(CASE WHEN status = 'CONFIRMED_POSITIVE' THEN 1 ELSE 0 END) as positive_count,
                    SUM(CASE WHEN status = 'REJECTED_NORMAL' THEN 1 ELSE 0 END) as negative_count
                FROM anomaly_event
                WHERE experiment_run_id = ?
            """, (experiment_run_id,))

            stats = cursor.fetchone()
            if stats:
                total_candidates, positive_count, negative_count = stats

                # 計算總數據池大小（基於實驗中使用的數據集）
                cursor.execute("""
                    SELECT SUM(ard_counts.total_records) as total_data_pool_size
                    FROM (
                        SELECT DISTINCT dataset_id, COUNT(*) as total_records
                        FROM analysis_ready_data ard
                        WHERE ard.dataset_id IN (
                            SELECT DISTINCT ae.dataset_id
                            FROM anomaly_event ae
                            WHERE ae.experiment_run_id = ?
                        )
                        GROUP BY dataset_id
                    ) ard_counts
                """, (experiment_run_id,))

                total_data_pool_result = cursor.fetchone()
                total_data_pool_size = total_data_pool_result[0] if total_data_pool_result and total_data_pool_result[0] else 0

                # 計算總數據池中的正標籤數（基於 AnalysisReadyData 中的 is_positive_label）
                cursor.execute("""
                    SELECT SUM(positive_counts.positive_labels) as total_positive_labels
                    FROM (
                        SELECT dataset_id, COUNT(*) as positive_labels
                        FROM analysis_ready_data ard
                        WHERE ard.dataset_id IN (
                            SELECT DISTINCT ae.dataset_id
                            FROM anomaly_event ae
                            WHERE ae.experiment_run_id = ?
                        ) AND ard.is_positive_label = 1
                        GROUP BY dataset_id
                    ) positive_counts
                """, (experiment_run_id,))

                total_positive_result = cursor.fetchone()
                total_positive_in_pool = total_positive_result[0] if total_positive_result and total_positive_result[0] else 0

                # 計算總數據池中的負標籤數
                total_negative_in_pool = total_data_pool_size - total_positive_in_pool

                cursor.execute("""
                    UPDATE experiment_run
                    SET candidate_count = ?,
                        positive_label_count = ?,
                        negative_label_count = ?,
                        total_data_pool_size = ?
                    WHERE id = ?
                """, (total_candidates, total_positive_in_pool, total_negative_in_pool, total_data_pool_size, experiment_run_id))

                logger.info(f"Bulk experiment update: Updated experiment {experiment_run_id} with pool stats: total_pool={total_data_pool_size}, positive={total_positive_in_pool}, negative={total_negative_in_pool}, candidates={total_candidates}")

            # 提交事務
            conn.commit()

            logger.info(f"Successfully bulk reviewed {event_count} events for experiment {experiment_run_id} as {status}")

            return {
                "success": True,
                "message": f"Successfully reviewed {event_count} events",
                "updated_events": event_ids,
                "total_updated": event_count,
                "status": status,
                "reviewer_id": reviewer_id,
                "review_timestamp": current_timestamp,
                "experiment_run_id": experiment_run_id
            }

        except Exception as e:
            # 回滾事務
            conn.rollback()
            raise e

        finally:
            conn.close()

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error bulk reviewing events by experiment: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to bulk review events by experiment: {str(e)}")

@case_study_v2_router.get("/anomaly-events/{event_id}")
async def get_anomaly_event_detail(event_id: str):
    """
    獲取單一異常事件的詳細資訊
    """
    try:
        import sqlite3

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT ae.id, ae.event_id, ae.dataset_id, ae.line, ae.event_timestamp, ae.detection_rule,
                   ae.score, ae.status, ae.data_window, ae.reviewer_id, ae.review_timestamp,
                   ae.justification_notes, ae.experiment_run_id, ae.created_at, ae.name
            FROM anomaly_event ae
            WHERE ae.id = ?
        """, (event_id,))

        event_row = cursor.fetchone()

        if not event_row:
            conn.close()
            raise HTTPException(status_code=404, detail="Anomaly event not found")

        # 轉換為字典格式
        columns = [desc[0] for desc in cursor.description]
        event_dict = dict(zip(columns, event_row))

        # 解析 data_window 格式 (可能是字符串或 JSON)
        if event_dict['data_window']:
            try:
                # 嘗試解析為 JSON
                event_dict['data_window'] = json.loads(event_dict['data_window'])
            except (json.JSONDecodeError, TypeError):
                # 如果不是 JSON，可能是時間範圍字符串格式 [start - end]
                window_str = event_dict['data_window']
                if window_str.startswith('[') and ' - ' in window_str:
                    # 解析 "[2025-07-27T10:13:00.000Z - 2025-07-27T14:03:00.000Z]" 格式
                    times = window_str.strip('[]').split(' - ')
                    if len(times) == 2:
                        event_dict['data_window'] = {
                            'startTime': times[0].strip(),
                            'endTime': times[1].strip(),
                            'duration': window_str
                        }
                    else:
                        event_dict['data_window'] = {'raw': window_str}
                else:
                    event_dict['data_window'] = {'raw': window_str}

        # 添加 metadata 欄位用於前端兼容
        event_dict['metadata'] = {}

        conn.close()

        logger.info(f"Retrieved anomaly event detail for {event_id}")
        return event_dict

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching anomaly event {event_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch anomaly event: {str(e)}")

@case_study_v2_router.get("/anomaly-events/{event_id}/data")
async def get_data_for_event(
    event_id: str,
    start_time: str = None,
    end_time: str = None
):
    """
    獲取指定異常事件的時間窗口內的電力數據，用於圖表視覺化
    這是 Stage 2 審核介面的核心 API - 新版本直接使用事件 ID
    支援自定義時間範圍參數 start_time 和 end_time
    """
    try:
        import sqlite3
        from datetime import datetime

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 1. 首先獲取異常事件信息
        cursor.execute("""
            SELECT ae.dataset_id, ae.data_window
            FROM anomaly_event ae
            WHERE ae.id = ?
        """, (event_id,))

        event_result = cursor.fetchone()
        if not event_result:
            conn.close()
            raise HTTPException(status_code=404, detail="Anomaly event not found")

        dataset_id, data_window_str = event_result

        # 2. 確定時間範圍 - 優先使用傳入的參數，否則使用事件的 data_window
        if start_time and end_time:
            # 使用前端傳入的自定義時間範圍
            query_start_time = start_time
            query_end_time = end_time
        else:
            # 使用事件原始的 data_window 時間範圍
            try:
                data_window = json.loads(data_window_str)
                query_start_time = data_window.get('startTime')
                query_end_time = data_window.get('endTime')
            except (json.JSONDecodeError, TypeError):
                # 處理舊格式的 data_window
                conn.close()
                raise HTTPException(status_code=400, detail="Invalid data_window format in event")

        # 3. 直接用 dataset_id 查詢 analysis_ready_data
        cursor.execute("""
            SELECT timestamp, raw_wattage_l1, raw_wattage_l2, wattage_110v, wattage_220v, wattage_total, is_positive_label
            FROM analysis_ready_data
            WHERE dataset_id = ?
            AND timestamp BETWEEN ? AND ?
            ORDER BY timestamp
        """, (dataset_id, query_start_time, query_end_time))

        data_rows = cursor.fetchall()

        # 4. 轉換為前端需要的格式
        time_series_data = []
        for row in data_rows:
            time_series_data.append({
                "timestamp": row[0],
                "rawWattageL1": row[1],
                "rawWattageL2": row[2],
                "wattage110v": row[3],
                "wattage220v": row[4],
                "wattageTotal": row[5],
                "isPositiveLabel": bool(row[6])
            })

        conn.close()

        logger.info(f"Retrieved {len(time_series_data)} data points for event {event_id}, time range: {query_start_time} to {query_end_time}")
        return time_series_data

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching data for event {event_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch event data: {str(e)}")

@case_study_v2_router.get("/data-for-window")
async def get_data_for_window(
    meter_id: str,
    start_time: str,
    end_time: str
):
    """
    獲取指定時間窗口內的電力數據，用於圖表視覺化
    這是 Stage 2 審核介面的核心 API
    注意：這個 API 保留是為了向後兼容，建議使用新的 /anomaly-events/{event_id}/data
    """
    try:
        import sqlite3
        from datetime import datetime

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 驗證時間格式並轉換
        try:
            start_dt = datetime.fromisoformat(start_time.replace('Z', '+00:00'))
            end_dt = datetime.fromisoformat(end_time.replace('Z', '+00:00'))

            # 轉換為 SQLite 格式
            start_formatted = start_dt.strftime('%Y-%m-%d %H:%M:%S')
            end_formatted = end_dt.strftime('%Y-%m-%d %H:%M:%S')

        except ValueError as e:
            raise HTTPException(status_code=400, detail=f"Invalid datetime format: {str(e)}")

        # 查詢數據 - 根據 meter_id 從 analysis_datasets 查找關聯的房間
        cursor.execute("""
            SELECT room FROM analysis_datasets
            WHERE meter_id_l1 = ? OR meter_id_l2 = ? OR id LIKE ?
            LIMIT 1
        """, (meter_id, meter_id, f"%{meter_id}%"))

        room_result = cursor.fetchone()
        data_rows = []

        if room_result:
            room = room_result[0]
            # 使用房間信息查詢數據
            cursor.execute("""
                SELECT ard.timestamp, ard.wattage_total, ard.wattage_110v, ard.wattage_220v
                FROM analysis_ready_data ard
                JOIN analysis_datasets ad ON ard.dataset_id = ad.id
                WHERE ad.room = ?
                AND ard.timestamp BETWEEN ? AND ?
                ORDER BY ard.timestamp ASC
                LIMIT 1000
            """, (room, start_formatted, end_formatted))

            data_rows = cursor.fetchall()

        # 如果還是沒有數據，嘗試直接根據房間匹配
        if not data_rows and 'Room' in meter_id:
            # 提取房間號，例如從 "Room R041 Analysis Dataset_L1" 提取 "R041"
            import re
            room_match = re.search(r'Room\s+([A-Z0-9]+)', meter_id)
            if room_match:
                room_code = room_match.group(1)
                cursor.execute("""
                    SELECT ard.timestamp, ard.wattage_total, ard.wattage_110v, ard.wattage_220v
                    FROM analysis_ready_data ard
                    WHERE ard.room LIKE ?
                    AND ard.timestamp BETWEEN ? AND ?
                    ORDER BY ard.timestamp ASC
                    LIMIT 1000
                """, (f"%{room_code}%", start_formatted, end_formatted))

                data_rows = cursor.fetchall()

        # 轉換為 JSON 格式
        result = []
        for row in data_rows:
            timestamp, wattage_total, wattage_110v, wattage_220v = row
            result.append({
                'timestamp': timestamp,
                'wattageTotal': wattage_total or 0,
                'wattage110v': wattage_110v or 0,
                'wattage220v': wattage_220v or 0
            })

        conn.close()

        logger.info(f"Retrieved {len(result)} data points for meter {meter_id} between {start_time} and {end_time}")

        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching data for window: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch data: {str(e)}")

@case_study_v2_router.patch("/anomaly-events/{event_id}/review")
async def review_anomaly_event(event_id: str, request: dict):
    """
    提交異常事件的審核結果
    這是 Stage 2 的核心業務邏輯，包含資料庫事務處理
    """
    try:
        import sqlite3

        # 解析請求參數
        status = request.get("status")
        reviewer_id = request.get("reviewer_id")
        justification_notes = request.get("justification_notes", "")

        # 驗證必需參數
        if not status or not reviewer_id:
            raise HTTPException(status_code=400, detail="status and reviewer_id are required")

        # 驗證狀態值
        valid_statuses = ["CONFIRMED_POSITIVE", "REJECTED_NORMAL"]
        if status not in valid_statuses:
            raise HTTPException(status_code=400, detail=f"Invalid status. Must be one of: {valid_statuses}")

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)

        try:
            # 開始事務
            conn.execute("BEGIN TRANSACTION")
            cursor = conn.cursor()

            # 1. 查詢並驗證異常事件
            cursor.execute("""
                SELECT id, dataset_id, event_timestamp, status, experiment_run_id
                FROM anomaly_event
                WHERE id = ?
            """, (event_id,))

            event_row = cursor.fetchone()
            if not event_row:
                raise HTTPException(status_code=404, detail="Anomaly event not found")

            current_status = event_row[3]
            if current_status != "UNREVIEWED":
                raise HTTPException(status_code=400, detail="Event has already been reviewed")

            event_dataset_id = event_row[1]
            event_timestamp = event_row[2]
            experiment_run_id = event_row[4]

            # 2. 更新異常事件狀態
            current_timestamp = get_current_datetime()

            cursor.execute("""
                UPDATE anomaly_event
                SET status = ?, reviewer_id = ?, justification_notes = ?,
                    review_timestamp = ?, updated_at = ?
                WHERE id = ?
            """, (status, reviewer_id, justification_notes, current_timestamp, current_timestamp, event_id))

            # 3. 【關鍵步驟】如果確認為異常，更新相關的 AnalysisReadyData
            if status == "CONFIRMED_POSITIVE":
                # 直接使用 dataset_id 和 timestamp 找到對應的 analysis_ready_data 記錄
                cursor.execute("""
                    UPDATE analysis_ready_data
                    SET is_positive_label = 1, source_anomaly_event_id = ?
                    WHERE dataset_id = ? AND timestamp = ?
                """, (event_id, event_dataset_id, event_timestamp))

                # 如果沒有找到完全匹配的記錄，嘗試時間範圍匹配
                if cursor.rowcount == 0:
                    from datetime import datetime, timedelta

                    # 解析事件時間戳
                    try:
                        event_dt = datetime.fromisoformat(event_timestamp.replace('Z', '+00:00'))
                        # 創建時間窗口 (±5分鐘)
                        start_window = (event_dt - timedelta(minutes=5)).strftime('%Y-%m-%d %H:%M:%S')
                        end_window = (event_dt + timedelta(minutes=5)).strftime('%Y-%m-%d %H:%M:%S')

                        # 查找對應的數據集和時間範圍
                        cursor.execute("""
                            SELECT id
                            FROM analysis_ready_data
                            WHERE dataset_id = ?
                            AND timestamp BETWEEN ? AND ?
                            ORDER BY ABS(julianday(timestamp) - julianday(?)) ASC
                            LIMIT 1
                        """, (event_dataset_id, start_window, end_window, event_timestamp))

                        matching_record = cursor.fetchone()
                        if matching_record:
                            cursor.execute("""
                                UPDATE analysis_ready_data
                                SET is_positive_label = 1, source_anomaly_event_id = ?
                                WHERE id = ?
                            """, (event_id, matching_record[0]))

                            logger.info(f"Updated analysis_ready_data record {matching_record[0]} for event {event_id}")
                        else:
                            logger.warning(f"Could not find matching analysis_ready_data for event {event_id}")

                    except Exception as dt_error:
                        logger.error(f"Error processing timestamp for event {event_id}: {dt_error}")

            # 4. 更新實驗運行的統計數據
            cursor.execute("""
                SELECT
                    COUNT(*) as total_candidates,
                    SUM(CASE WHEN status = 'CONFIRMED_POSITIVE' THEN 1 ELSE 0 END) as positive_count,
                    SUM(CASE WHEN status = 'REJECTED_NORMAL' THEN 1 ELSE 0 END) as negative_count
                FROM anomaly_event
                WHERE experiment_run_id = ?
            """, (experiment_run_id,))

            stats_row = cursor.fetchone()
            if stats_row:
                total_candidates, positive_count, negative_count = stats_row

                # 計算總數據池大小（基於實驗中使用的數據集）
                cursor.execute("""
                    SELECT SUM(ard_counts.total_records) as total_data_pool_size
                    FROM (
                        SELECT DISTINCT dataset_id, COUNT(*) as total_records
                        FROM analysis_ready_data ard
                        WHERE ard.dataset_id IN (
                            SELECT DISTINCT ae.dataset_id
                            FROM anomaly_event ae
                            WHERE ae.experiment_run_id = ?
                        )
                        GROUP BY dataset_id
                    ) ard_counts
                """, (experiment_run_id,))

                total_data_pool_result = cursor.fetchone()
                total_data_pool_size = total_data_pool_result[0] if total_data_pool_result and total_data_pool_result[0] else 0

                # 計算總數據池中的正標籤數（基於 AnalysisReadyData 中的 is_positive_label）
                cursor.execute("""
                    SELECT SUM(positive_counts.positive_labels) as total_positive_labels
                    FROM (
                        SELECT dataset_id, COUNT(*) as positive_labels
                        FROM analysis_ready_data ard
                        WHERE ard.dataset_id IN (
                            SELECT DISTINCT ae.dataset_id
                            FROM anomaly_event ae
                            WHERE ae.experiment_run_id = ?
                        ) AND ard.is_positive_label = 1
                        GROUP BY dataset_id
                    ) positive_counts
                """, (experiment_run_id,))

                total_positive_result = cursor.fetchone()
                total_positive_in_pool = total_positive_result[0] if total_positive_result and total_positive_result[0] else 0

                # 計算總數據池中的負標籤數
                total_negative_in_pool = total_data_pool_size - total_positive_in_pool

                cursor.execute("""
                    UPDATE experiment_run
                    SET candidate_count = ?,
                        positive_label_count = ?,
                        negative_label_count = ?,
                        total_data_pool_size = ?,
                        updated_at = ?
                    WHERE id = ?
                """, (total_candidates, total_positive_in_pool, total_negative_in_pool, total_data_pool_size, current_timestamp, experiment_run_id))

                logger.info(f"Updated experiment {experiment_run_id} with pool stats: total_pool={total_data_pool_size}, positive={total_positive_in_pool}, negative={total_negative_in_pool}, candidates={total_candidates}")

            # 4.5. 更新 AnalysisDataset 的 positiveLabels
            new_positive_count = update_analysis_dataset_positive_labels(cursor, event_dataset_id)
            if new_positive_count is not None:
                logger.info(f"Updated AnalysisDataset {event_dataset_id} positiveLabels to {new_positive_count}")

            # 提交事務
            conn.commit()

            logger.info(f"Successfully reviewed event {event_id} with status {status} by reviewer {reviewer_id}")

            return {
                "success": True,
                "message": "Event reviewed successfully",
                "event_id": event_id,
                "status": status,
                "reviewer_id": reviewer_id,
                "review_timestamp": current_timestamp
            }

        except Exception as e:
            # 回滾事務
            conn.rollback()
            raise e

        finally:
            conn.close()

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error reviewing event {event_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to review event: {str(e)}")

# ========== End of Stage 2 API Routes ==========


@case_study_v2_router.post("/training-jobs")
async def start_training_job(request: dict):
    """Starts a new model training job"""
    try:
        # 直接使用主資料庫創建訓練作業
        import sqlite3
        import json

        # 解析請求參數
        model_name = request.get("model_name")
        scenario_type = request.get("scenario_type")
        experiment_run_id = request.get("experiment_run_id")
        training_config = request.get("training_config", {})
        data_source_config = request.get("data_source_config", {})

        if not model_name or not scenario_type or not experiment_run_id:
            raise HTTPException(status_code=400, detail="model_name, scenario_type, and experiment_run_id are required")

        # 生成作業 ID
        job_id = str(uuid.uuid4())

        # 連接到主資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 檢查實驗運行是否存在
        cursor.execute('SELECT id FROM experiment_run WHERE id = ?', (experiment_run_id,))
        if not cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=404, detail="Experiment run not found")

        # 創建訓練模型記錄
        current_timestamp = get_current_datetime()
        trained_model_id = str(uuid.uuid4())

        cursor.execute('''
            INSERT INTO trained_models
            (id, name, scenario_type, status, experiment_run_id, model_config,
             data_source_config, created_at, job_id)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            trained_model_id,
            model_name,
            scenario_type,
            "PENDING",
            experiment_run_id,
            json.dumps(training_config),
            json.dumps(data_source_config),
            current_timestamp,
            job_id
        ))

        conn.commit()
        conn.close()

        # 注意：實際的訓練邏輯需要額外實現
        # 這裡只是創建記錄，實際訓練需要背景任務
        logger.info(f"Training job {job_id} created for model {model_name}")
        logger.warning("Actual model training implementation is not available - job created in PENDING status")

        return {
            "job_id": job_id,
            "trained_model_id": trained_model_id,
            "status": "PENDING",
            "message": "Training job created successfully (actual training requires case-study-v2 modules)"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error starting training job: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@case_study_v2_router.post("/evaluation-jobs")
async def start_evaluation_job(
    request: dict,  # We'll update this to use Pydantic model later
    background_tasks: BackgroundTasks,
    evaluator: Any = Depends(get_model_evaluator)
):
    """Starts a new model evaluation job as a background task"""
    try:
        # 解析請求參數
        evaluation_name = request.get("evaluation_name")
        scenario_type = request.get("scenario_type")
        trained_model_id = request.get("trained_model_id")
        test_set_source = request.get("test_set_source", {})

        if not evaluation_name or not scenario_type or not trained_model_id:
            raise HTTPException(status_code=400, detail="evaluation_name, scenario_type, and trained_model_id are required")

        # 生成作業 ID
        job_id = str(uuid.uuid4())
        evaluation_run_id = str(uuid.uuid4())

        # 直接使用主資料庫創建評估作業
        import sqlite3
        import json

        # 連接到主資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 檢查訓練模型是否存在
        cursor.execute('SELECT id FROM trained_models WHERE id = ?', (trained_model_id,))
        if not cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=404, detail="Trained model not found")

        # 創建評估運行記錄
        current_timestamp = get_current_datetime()

        cursor.execute('''
            INSERT INTO evaluation_runs
            (id, name, scenario_type, status, trained_model_id, test_set_source,
             created_at, job_id)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            evaluation_run_id,
            evaluation_name,
            scenario_type,
            "RUNNING",  # Changed from PENDING to RUNNING
            trained_model_id,
            json.dumps(test_set_source),
            current_timestamp,
            job_id
        ))

        conn.commit()
        conn.close()

        # 【關鍵變更】將實際的評估工作添加到背景任務
        # Create a mock config object for the evaluator
        class MockConfig:
            def __init__(self, evaluation_name, scenario_type, trained_model_id, test_set_source):
                self.evaluation_name = evaluation_name
                self.scenario_type = scenario_type
                self.trained_model_id = trained_model_id
                self.test_set_source = test_set_source

        config = MockConfig(evaluation_name, scenario_type, trained_model_id, test_set_source)

        background_tasks.add_task(
            evaluator.evaluate_model,
            job_id=job_id,
            evaluation_run_id=evaluation_run_id,
            config=config
        )

        logger.info(f"Evaluation job {job_id} for evaluation '{evaluation_name}' has been successfully scheduled.")

        return {
            "job_id": job_id,
            "evaluation_run_id": evaluation_run_id,
            "status": "RUNNING",  # Changed from PENDING
            "message": "Evaluation job has been scheduled and is running in the background."
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error starting evaluation job: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@case_study_v2_router.get("/experiment-runs/{run_id}/history")
async def get_experiment_history(run_id: str):
    """Retrieves the full experiment history for an ExperimentRun"""
    try:
        # 使用資料庫
        import sqlite3
        import json

        # 連接到正確的 Prisma 資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 檢查實驗運行是否存在
        cursor.execute('SELECT id, name, status FROM experiment_run WHERE id = ?', (run_id,))
        experiment = cursor.fetchone()

        if not experiment:
            conn.close()
            raise HTTPException(status_code=404, detail="Experiment run not found")

        # 獲取訓練模型
        cursor.execute('''
            SELECT id, name, scenario_type, status, experiment_run_id,
                   created_at, completed_at, training_metrics
            FROM trained_models
            WHERE experiment_run_id = ?
            ORDER BY created_at DESC
        ''', (run_id,))
        trained_models_data = cursor.fetchall()

        # 獲取評估運行
        cursor.execute('''
            SELECT er.id, er.name, er.scenario_type, er.status, er.trained_model_id,
                   er.test_set_source, er.evaluation_metrics, er.created_at, er.completed_at
            FROM evaluation_runs er
            LEFT JOIN trained_models tm ON er.trained_model_id = tm.id
            WHERE tm.experiment_run_id = ?
            ORDER BY er.created_at DESC
        ''', (run_id,))
        evaluation_runs_data = cursor.fetchall()

        # 轉換時間戳記的輔助函數
        from datetime import datetime
        def convert_timestamp(ts):
            if not ts:
                return None
            try:
                if isinstance(ts, str):
                    return ts
                else:
                    return datetime.fromtimestamp(ts / 1000).isoformat() + "Z"
            except:
                return str(ts)

        # 構建歷史回應
        history = {
            "experiment_run": {
                "id": experiment[0],
                "name": experiment[1],
                "status": experiment[2]
            },
            "trained_models": [],
            "evaluation_runs": []
        }

        # 添加訓練模型資訊
        for model in trained_models_data:
            # 解析 training_metrics 並提取測試階段指標
            evaluation_metrics = {}
            try:
                if model[7]:  # training_metrics
                    training_metrics = json.loads(model[7])
                    # 提取測試階段的三個關鍵指標
                    evaluation_metrics = {
                        "f1_score": training_metrics.get("final_test_f1_score"),
                        "recall": training_metrics.get("final_test_recall"),
                        "precision": training_metrics.get("final_test_precision")
                    }
            except json.JSONDecodeError:
                # 如果解析失敗，使用空字典
                evaluation_metrics = {}

            trained_model = {
                "id": model[0],
                "name": model[1],
                "scenario_type": model[2],
                "status": model[3],
                "experiment_run_id": model[4],
                "created_at": model[5],
                "completed_at": model[6],
                "evaluation_metrics": evaluation_metrics
            }

            history["trained_models"].append(trained_model)

        # 添加評估運行資訊
        for evaluation in evaluation_runs_data:
            evaluation_metrics = {}

            try:
                if evaluation[6]:  # evaluation_metrics
                    evaluation_metrics = json.loads(evaluation[6])
            except json.JSONDecodeError:
                pass

            history["evaluation_runs"].append({
                "id": evaluation[0],
                "name": evaluation[1],
                "scenario_type": evaluation[2],
                "status": evaluation[3],
                "trained_model_id": evaluation[4],
                "test_set_source": evaluation[5],
                "evaluation_metrics": evaluation_metrics,
                "created_at": evaluation[7],
                "completed_at": evaluation[8]
            })

        conn.close()

        logger.info(f"Successfully retrieved experiment history for {run_id}")
        logger.info(f"Found {len(history['trained_models'])} trained models and {len(history['evaluation_runs'])} evaluation runs")
        return history

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching experiment history for {run_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@case_study_v2_router.get("/analysis-datasets")
async def get_analysis_datasets():
    """Retrieves a list of available analysis datasets for dataset selection"""
    try:
        # 直接使用 SQLite 連接讀取 AnalysisDataset 資料表
        import sqlite3

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 查詢所有 AnalysisDataset 記錄
        cursor.execute('''
            SELECT id, name, description, building, floor, room,
                   start_date, end_date, occupant_type, meter_id_l1, meter_id_l2,
                   total_records, positive_labels, created_at
            FROM analysis_datasets
            ORDER BY building, floor, room
        ''')

        rows = cursor.fetchall()
        conn.close()

        # 轉換為字典格式
        result = []
        for row in rows:
            # 處理日期時間欄位
            start_date = row[6]
            end_date = row[7]
            created_at = row[13]

            # 如果是字串格式的日期，保持原樣；如果是時間戳，則轉換
            try:
                from datetime import datetime
                if isinstance(start_date, (int, float)):
                    start_date = datetime.fromtimestamp(start_date).isoformat() + "Z"
                elif isinstance(start_date, str) and not start_date.endswith('Z'):
                    start_date = start_date + "Z" if 'T' in start_date else start_date

                if isinstance(end_date, (int, float)):
                    end_date = datetime.fromtimestamp(end_date).isoformat() + "Z"
                elif isinstance(end_date, str) and not end_date.endswith('Z'):
                    end_date = end_date + "Z" if 'T' in end_date else end_date

                if isinstance(created_at, (int, float)):
                    created_at = datetime.fromtimestamp(created_at).isoformat() + "Z"
                elif isinstance(created_at, str) and not created_at.endswith('Z'):
                    created_at = created_at + "Z" if 'T' in created_at else created_at
            except:
                # 如果轉換失敗，保持原值
                pass

            result.append({
                "id": row[0],
                "name": row[1],
                "description": row[2],
                "building": row[3],
                "floor": row[4],
                "room": row[5],
                "startDate": start_date,
                "endDate": end_date,
                "occupantType": row[8],
                "meterIdL1": row[9],
                "meterIdL2": row[10],
                "totalRecords": row[11],
                "positiveLabels": row[12],
                "createdAt": created_at
            })

        logger.info(f"Successfully retrieved {len(result)} analysis datasets from database")
        return result

    except Exception as e:
        logger.error(f"Error fetching analysis datasets: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to retrieve analysis datasets: {str(e)}")

@case_study_v2_router.get("/models")
async def get_available_models():
    """Retrieves a list of trainable models for the selection dropdown"""
    try:
        models = [
            {
                "id": "nnpu_baseline",
                "name": "nnPU Baseline",
                "description": "Non-negative PU Learning with default parameters",
                "parameters": ["learning_rate", "batch_size", "epochs", "prior"]
            },
            {
                "id": "nnpu_advanced",
                "name": "nnPU Advanced",
                "description": "Non-negative PU Learning with custom parameters",
                "parameters": ["learning_rate", "batch_size", "epochs", "prior", "beta", "gamma"]
            }
        ]
        return models
    except Exception as e:
        logger.error(f"Error fetching available models: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@case_study_v2_router.get("/evaluation-runs/{run_id}")
async def get_evaluation_run(run_id: str):
    """Retrieves detailed results for a single EvaluationRun"""
    try:
        # 直接使用主資料庫讀取評估運行詳情
        import sqlite3
        import json

        # 連接到主資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 查詢特定評估運行
        cursor.execute('''
            SELECT er.id, er.name, er.scenario_type, er.status, er.trained_model_id,
                   er.test_set_source, er.evaluation_metrics, er.created_at, er.completed_at, er.job_id,
                   tm.name as model_name, tm.model_config
            FROM evaluation_runs er
            LEFT JOIN trained_models tm ON er.trained_model_id = tm.id
            WHERE er.id = ?
        ''', (run_id,))

        row = cursor.fetchone()

        if not row:
            conn.close()
            raise HTTPException(status_code=404, detail="Evaluation run not found")

        # 解析 JSON 欄位
        test_set_source = {}
        evaluation_metrics = {}
        model_config = {}

        try:
            if row[5]:  # test_set_source
                test_set_source = json.loads(row[5])
        except json.JSONDecodeError:
            pass

        try:
            if row[6]:  # evaluation_metrics
                evaluation_metrics = json.loads(row[6])
        except json.JSONDecodeError:
            pass

        try:
            if row[11]:  # model_config
                model_config = json.loads(row[11])
        except json.JSONDecodeError:
            pass

        # 轉換時間戳記
        from datetime import datetime
        created_at = None
        completed_at = None

        if row[7]:  # created_at
            try:
                if isinstance(row[7], str):
                    created_at = row[7]
                else:
                    created_at = datetime.fromtimestamp(row[7] / 1000).isoformat() + "Z"
            except:
                created_at = str(row[7])

        if row[8]:  # completed_at
            try:
                if isinstance(row[8], str):
                    completed_at = row[8]
                else:
                    completed_at = datetime.fromtimestamp(row[8] / 1000).isoformat() + "Z"
            except:
                completed_at = str(row[8])

        result = {
            "id": row[0],
            "name": row[1],
            "scenario_type": row[2],
            "status": row[3] or "UNKNOWN",
            "trained_model_id": row[4],
            "test_set_source": test_set_source,
            "evaluation_metrics": evaluation_metrics,
            "created_at": created_at,
            "completed_at": completed_at,
            "job_id": row[9],
            "model_info": {
                "name": row[10],
                "config": model_config
            }
        }

        conn.close()

        logger.info(f"Successfully retrieved evaluation run: {run_id}")
        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error fetching evaluation run {run_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@case_study_v2_router.patch("/experiment-runs/{run_id}/status")
async def update_experiment_status(run_id: str, request: dict):
    """
    更新實驗運行的狀態
    支持的狀態: CONFIGURING, LABELING, COMPLETED
    """
    try:
        import sqlite3

        # 解析請求參數
        new_status = request.get("status")
        if not new_status:
            raise HTTPException(status_code=400, detail="status is required")

        # 驗證狀態值
        valid_statuses = ["CONFIGURING", "LABELING", "COMPLETED"]
        if new_status not in valid_statuses:
            raise HTTPException(status_code=400, detail=f"Invalid status. Must be one of: {valid_statuses}")

        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 檢查實驗是否存在
        cursor.execute('SELECT id, name, status FROM experiment_run WHERE id = ?', (run_id,))
        experiment = cursor.fetchone()

        if not experiment:
            conn.close()
            raise HTTPException(status_code=404, detail="Experiment run not found")

        old_status = experiment[2]

        # 更新實驗狀態
        current_timestamp = get_current_datetime()
        cursor.execute("""
            UPDATE experiment_run
            SET status = ?, updated_at = ?
            WHERE id = ?
        """, (new_status, current_timestamp, run_id))

        conn.commit()
        conn.close()

        logger.info(f"Updated experiment {run_id} status from {old_status} to {new_status}")

        return {
            "success": True,
            "message": f"Experiment status updated successfully",
            "experiment_id": run_id,
            "old_status": old_status,
            "new_status": new_status,
            "updated_at": current_timestamp
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error updating experiment status: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to update experiment status: {str(e)}")


# =============================================================================
# Stage 3: Trained Models and Evaluation Runs API
# =============================================================================

@case_study_v2_router.get("/trained-models")
async def get_trained_models(experiment_run_id: Optional[str] = None):
    """List trained models, optionally filtered by experiment run ID"""
    try:
        import sqlite3
        import json

        # Connect to database
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # Build query based on filter
        if experiment_run_id:
            cursor.execute('''
                SELECT id, name, scenario_type, status, experiment_run_id, model_config, data_source_config,
                       model_path, training_metrics, training_data_info, job_id, created_at, started_at, completed_at
                FROM trained_models
                WHERE experiment_run_id = ?
                ORDER BY created_at DESC
            ''', (experiment_run_id,))
        else:
            cursor.execute('''
                SELECT id, name, scenario_type, status, experiment_run_id, model_config, data_source_config,
                       model_path, training_metrics, training_data_info, job_id, created_at, started_at, completed_at
                FROM trained_models
                ORDER BY created_at DESC
            ''')

        rows = cursor.fetchall()
        conn.close()

        # Convert to list of dicts
        models = []
        for row in rows:
            model_config = {}
            data_source_config = {}
            training_metrics = {}
            training_data_info = {}

            # Parse JSON fields
            try:
                if row[5]:  # model_config
                    model_config = json.loads(row[5])
            except json.JSONDecodeError:
                pass

            try:
                if row[6]:  # data_source_config
                    data_source_config = json.loads(row[6])
            except json.JSONDecodeError:
                pass

            try:
                if row[8]:  # training_metrics
                    training_metrics = json.loads(row[8])
            except json.JSONDecodeError:
                pass

            try:
                if row[9]:  # training_data_info
                    training_data_info = json.loads(row[9])
            except json.JSONDecodeError:
                pass

            models.append({
                "id": row[0],
                "name": row[1],
                "scenarioType": row[2],
                "status": row[3] or "PENDING",
                "model_config": model_config,
                "data_source_config": data_source_config,
                "model_path": row[7],
                "training_metrics": training_metrics,
                "training_data_info": training_data_info,
                "job_id": row[10],
                "created_at": row[11],
                "completed_at": row[13],
                "experiment_run_id": row[4]
            })

        return models

    except Exception as e:
        logger.error(f"Error fetching trained models: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@case_study_v2_router.post("/trained-models")
async def create_trained_model(request: dict):
    """Create a new trained model and start training job"""
    try:
        import sqlite3
        import json
        import uuid

        logger.info(f"📥 Received training model creation request: {request.get('name', 'Unknown')}")

        # Validate request
        required_fields = ["name", "scenario_type", "experimentRunId", "modelConfig", "dataSourceConfig"]
        for field in required_fields:
            if field not in request:
                logger.error(f"❌ Missing required field: {field}")
                raise HTTPException(status_code=400, detail=f"Missing required field: {field}")

        # Generate IDs
        model_id = str(uuid.uuid4())
        job_id = str(uuid.uuid4())
        current_time = get_current_datetime()

        logger.info(f"🆔 Generated IDs - Model: {model_id}, Job: {job_id}")

        # Connect to database
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        logger.info(f"💾 Inserting new trained model to database")

        # Process model and data source configurations
        model_config_str = request["modelConfig"]
        data_source_config_str = request["dataSourceConfig"]

        # Parse and extract P and U data source IDs
        if isinstance(data_source_config_str, dict):
            data_source_config = data_source_config_str
        else:
            data_source_config = json.loads(data_source_config_str)

        # 🆕 生成隨機種子確保可複現性
        import random
        import time
        random_seed = int(time.time() * 1000000) % 1000000  # 6位數隨機種子

        logger.info(f"🎲 Generated random seed for reproducible training: {random_seed}")

        # 🆕 構建增強的 dataSourceConfig (靜態子集法配方)
        enhanced_data_source_config = {
            "source_dataset_ids": data_source_config.get("selectedDatasets", []),
            "positive_data_source_ids": data_source_config.get("positiveDataSourceIds", []),
            "unlabeled_data_source_ids": data_source_config.get("unlabeledDataSourceIds", []),
            "time_range": data_source_config.get("timeRange", {}),
            "split_ratios": {
                "train": data_source_config.get("trainRatio", 70) / 100,
                "validation": data_source_config.get("validationRatio", 20) / 100,
                "test": data_source_config.get("testRatio", 10) / 100
            },
            "split_method": "time_based",
            "training_sampling": {
                "method": "static_subset",
                "u_sample_ratio": data_source_config.get("uSampleRatio", 0.1),
                "random_seed": random_seed  # 🔑 關鍵：可複現性
            }
        }

        logger.info(f"🔧 Enhanced data source config with static subset method:")
        logger.info(f"   - Split ratios: {enhanced_data_source_config['split_ratios']}")
        logger.info(f"   - U sample ratio: {enhanced_data_source_config['training_sampling']['u_sample_ratio']}")
        logger.info(f"   - Random seed: {enhanced_data_source_config['training_sampling']['random_seed']}")

        # Extract P and U data source IDs for enhanced training
        positive_data_source_ids = enhanced_data_source_config.get("positive_data_source_ids", [])
        unlabeled_data_source_ids = enhanced_data_source_config.get("unlabeled_data_source_ids", [])

        logger.info(f"🔍 P data sources (positive): {positive_data_source_ids}")
        logger.info(f"🔍 U data sources (unlabeled): {unlabeled_data_source_ids}")

        # Serialize configurations for database storage
        if isinstance(model_config_str, dict):
            model_config_json = json.dumps(model_config_str)
        else:
            model_config_json = model_config_str

        # 🆕 使用增強的配置進行儲存
        enhanced_data_source_config_json = json.dumps(enhanced_data_source_config)

        logger.info(f"🔍 Model config processing:")
        logger.info(f"   - Original type: {type(model_config_str)}")
        logger.info(f"   - Final storage: {model_config_json}")

        # Insert new trained model
        cursor.execute('''
            INSERT INTO trained_models (
                id, name, scenario_type, status, experiment_run_id,
                model_config, data_source_config, job_id, created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            model_id,
            request["name"],
            request["scenario_type"],
            "PENDING",
            request["experimentRunId"],
            model_config_json,
            enhanced_data_source_config_json,  # 🆕 使用增強配置
            job_id,
            current_time
        ))

        conn.commit()
        conn.close()

        logger.info(f"🚀 啟動異步訓練作業 | Starting asynchronous training job: {job_id}")
        # ✅ 立即啟動異步任務，不等待結果
        asyncio.create_task(run_training_job(model_id, job_id))

        return {
            "id": model_id,
            "name": request["name"],
            "scenario_type": request["scenario_type"],  # ✅ 修正字段名稱
            "status": "PENDING",
            "modelConfig": request["modelConfig"],
            "dataSourceConfig": request["dataSourceConfig"],
            "jobId": job_id,
            "createdAt": current_time,
            "experimentRunId": request["experimentRunId"]
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating trained model: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@case_study_v2_router.delete("/trained-models/{model_id}")
async def delete_trained_model(model_id: str):
    """Delete a trained model and all its associated evaluations"""
    try:
        import sqlite3

        logger.info(f"🗑️ 刪除訓練模型請求 | Delete trained model request: {model_id}")

        # Connect to database
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # Check if model exists
        cursor.execute('SELECT name FROM trained_models WHERE id = ?', (model_id,))
        model = cursor.fetchone()

        if not model:
            conn.close()
            logger.warning(f"⚠️ 模型不存在 | Model not found: {model_id}")
            raise HTTPException(status_code=404, detail="Trained model not found")

        model_name = model[0]
        logger.info(f"📋 找到模型 | Found model: {model_name}")

        # Delete all evaluation runs for this model first (due to foreign key constraints)
        cursor.execute('SELECT COUNT(*) FROM evaluation_runs WHERE trained_model_id = ?', (model_id,))
        eval_count = cursor.fetchone()[0]

        if eval_count > 0:
            logger.info(f"🗑️ 刪除 {eval_count} 個評估結果 | Deleting {eval_count} evaluation results")
            cursor.execute('DELETE FROM evaluation_runs WHERE trained_model_id = ?', (model_id,))

        # Delete the trained model
        cursor.execute('DELETE FROM trained_models WHERE id = ?', (model_id,))

        # Check if deletion was successful
        if cursor.rowcount == 0:
            conn.close()
            logger.error(f"❌ 刪除失敗 | Failed to delete model: {model_id}")
            raise HTTPException(status_code=404, detail="Failed to delete trained model")

        conn.commit()
        conn.close()

        logger.info(f"✅ 成功刪除模型和相關評估 | Successfully deleted model and {eval_count} evaluations: {model_name}")

        return {
            "success": True,
            "message": f"Successfully deleted model '{model_name}' and {eval_count} associated evaluations",
            "deletedModelId": model_id,
            "deletedEvaluations": eval_count
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"❌ 刪除模型時發生錯誤 | Error deleting trained model: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@case_study_v2_router.patch("/trained-models/{model_id}/rename")
async def rename_trained_model(model_id: str, request: dict):
    """Rename a trained model"""
    try:


        new_name = request.get("new_name", "").strip()
        if not new_name:
            raise HTTPException(status_code=400, detail="新名稱不能為空 | New name cannot be empty")

        if len(new_name) > 100:
            raise HTTPException(status_code=400, detail="名稱長度不能超過100個字符 | Name cannot exceed 100 characters")

        logger.info(f"🏷️ 重命名訓練模型請求 | Rename trained model request: {model_id} -> {new_name}")

        import sqlite3

        # Connect to database
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 先檢查模型是否存在
        cursor.execute('SELECT name FROM trained_models WHERE id = ?', (model_id,))
        result = cursor.fetchone()

        if not result:
            conn.close()
            logger.error(f"❌ 模型不存在 | Model not found: {model_id}")
            raise HTTPException(status_code=404, detail="訓練模型不存在 | Trained model not found")

        old_name = result[0]

        # 檢查新名稱是否與其他模型重複
        cursor.execute('SELECT id FROM trained_models WHERE name = ? AND id != ?', (new_name, model_id))
        if cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=400, detail="模型名稱已存在 | Model name already exists")

        # 更新模型名稱
        cursor.execute('UPDATE trained_models SET name = ? WHERE id = ?', (new_name, model_id))

        if cursor.rowcount == 0:
            conn.close()
            logger.error(f"❌ 重命名失敗 | Failed to rename model: {model_id}")
            raise HTTPException(status_code=404, detail="Failed to rename trained model")

        conn.commit()
        conn.close()

        logger.info(f"✅ 成功重命名模型 | Successfully renamed model: {old_name} -> {new_name}")

        return {
            "success": True,
            "message": f"Successfully renamed model from '{old_name}' to '{new_name}'",
            "modelId": model_id,
            "oldName": old_name,
            "newName": new_name
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"❌ 重命名模型時發生錯誤 | Error renaming trained model: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@case_study_v2_router.delete("/evaluation-runs/{evaluation_id}")
async def delete_evaluation_run(evaluation_id: str):
    """Delete a specific evaluation run. This operation is idempotent."""
    try:
        import sqlite3

        # Connect to database
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # Get name for logging before deleting
        cursor.execute('SELECT name FROM evaluation_runs WHERE id = ?', (evaluation_id,))
        result = cursor.fetchone()
        evaluation_name = result[0] if result else "Not Found"

        # Delete the evaluation run
        cursor.execute('DELETE FROM evaluation_runs WHERE id = ?', (evaluation_id,))
        rows_deleted = cursor.rowcount

        conn.commit()
        conn.close()

        if rows_deleted > 0:
            logger.info(f"✅ 成功刪除評估結果 | Successfully deleted evaluation run: {evaluation_name} (ID: {evaluation_id})")
            message = f"Successfully deleted evaluation run '{evaluation_name}'"
        else:
            logger.info(f"✅ 評估結果不存在，無需刪除 | Evaluation run not found, no deletion needed: {evaluation_id}")
            message = f"Evaluation run with ID '{evaluation_id}' was not found, but considered deleted."

        return {
            "message": message,
            "deletedEvaluationId": evaluation_id
        }

    except Exception as e:
        logger.error(f"❌ 刪除評估結果時發生錯誤 | Error deleting evaluation run: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@case_study_v2_router.patch("/evaluation-runs/{evaluation_id}/rename")
async def rename_evaluation_run(evaluation_id: str, request: dict):
    """Rename an evaluation run"""
    try:
        new_name = request.get("new_name", "").strip()
        if not new_name:
            raise HTTPException(status_code=400, detail="新名稱不能為空 | New name cannot be empty")

        if len(new_name) > 100:
            raise HTTPException(status_code=400, detail="名稱長度不能超過100個字符 | Name cannot exceed 100 characters")

        logger.info(f"🏷️ 重命名評估請求 | Rename evaluation request: {evaluation_id} -> {new_name}")

        import sqlite3

        # Connect to database
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 先檢查評估是否存在
        cursor.execute('SELECT name FROM evaluation_runs WHERE id = ?', (evaluation_id,))
        result = cursor.fetchone()

        if not result:
            conn.close()
            logger.error(f"❌ 評估不存在 | Evaluation not found: {evaluation_id}")
            raise HTTPException(status_code=404, detail="評估不存在 | Evaluation run not found")

        old_name = result[0]

        # 檢查新名稱是否與其他評估重複
        cursor.execute('SELECT id FROM evaluation_runs WHERE name = ? AND id != ?', (new_name, evaluation_id))
        if cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=400, detail="評估名稱已存在 | Evaluation name already exists")

        # 更新評估名稱
        cursor.execute('UPDATE evaluation_runs SET name = ? WHERE id = ?', (new_name, evaluation_id))

        if cursor.rowcount == 0:
            conn.close()
            logger.error(f"❌ 重命名失敗 | Failed to rename evaluation: {evaluation_id}")
            raise HTTPException(status_code=404, detail="Failed to rename evaluation run")

        conn.commit()
        conn.close()

        logger.info(f"✅ 成功重命名評估 | Successfully renamed evaluation: {old_name} -> {new_name}")

        return {
            "success": True,
            "message": f"Successfully renamed evaluation from '{old_name}' to '{new_name}'",
            "evaluationId": evaluation_id,
            "oldName": old_name,
            "newName": new_name
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"❌ 重命名評估時發生錯誤 | Error renaming evaluation run: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@case_study_v2_router.get("/evaluation-runs")
async def get_evaluation_runs(experiment_run_id: Optional[str] = None, trained_model_id: Optional[str] = None):
    """List evaluation runs, optionally filtered by experiment run ID or trained model ID"""
    try:
        import sqlite3
        import json

        # Connect to database
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # Build query based on filters
        base_query = '''
            SELECT er.id, er.name, er.scenario_type, er.status, er.trained_model_id,
                   er.test_set_source, er.evaluation_metrics, er.job_id, er.created_at, er.completed_at,
                   tm.name as model_name, tm.experiment_run_id
            FROM evaluation_runs er
            LEFT JOIN trained_models tm ON er.trained_model_id = tm.id
        '''

        params = []
        where_conditions = []

        if experiment_run_id:
            where_conditions.append("tm.experiment_run_id = ?")
            params.append(experiment_run_id)

        if trained_model_id:
            where_conditions.append("er.trained_model_id = ?")
            params.append(trained_model_id)

        if where_conditions:
            base_query += " WHERE " + " AND ".join(where_conditions)

        base_query += " ORDER BY er.created_at DESC"

        cursor.execute(base_query, params)
        rows = cursor.fetchall()
        conn.close()

        # Convert to list of dicts
        evaluation_runs = []
        for row in rows:
            test_set_source = {}
            evaluation_metrics = {}

            # Parse JSON fields
            try:
                if row[5]:  # test_set_source
                    test_set_source = json.loads(row[5])
            except json.JSONDecodeError:
                pass

            try:
                if row[6]:  # evaluation_metrics
                    evaluation_metrics = json.loads(row[6])
            except json.JSONDecodeError:
                pass

            evaluation_runs.append({
                "id": row[0],
                "name": row[1],
                "scenarioType": row[2],
                "status": row[3] or "PENDING",
                "trainedModelId": row[4],
                "testSetSource": test_set_source,
                "evaluationMetrics": evaluation_metrics,
                "jobId": row[7],
                "createdAt": row[8],
                "completedAt": row[9],
                "modelName": row[10],
                "experimentRunId": row[11]
            })

        return evaluation_runs

    except Exception as e:
        logger.error(f"Error fetching evaluation runs: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@case_study_v2_router.post("/evaluation-runs")
async def create_evaluation_run(request: dict):
    """Create a new evaluation run and start evaluation job"""
    try:
        import sqlite3
        import json
        import uuid

        # Validate request
        required_fields = ["name", "scenario_type", "trained_model_id", "testSetSource"]
        for field in required_fields:
            if field not in request:
                raise HTTPException(status_code=400, detail=f"Missing required field: {field}")

        # Check if trained model exists
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        cursor.execute('SELECT id FROM trained_models WHERE id = ?', (request["trained_model_id"],))
        if not cursor.fetchone():
            conn.close()
            raise HTTPException(status_code=404, detail="Trained model not found")

        # Generate IDs
        evaluation_id = str(uuid.uuid4())
        job_id = str(uuid.uuid4())
        current_time = get_current_datetime()

        # Insert new evaluation run
        cursor.execute('''
            INSERT INTO evaluation_runs (
                id, name, scenario_type, status, trained_model_id,
                test_set_source, job_id, created_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            evaluation_id,
            request["name"],
            request["scenario_type"],
            "PENDING",
            request["trained_model_id"],
            json.dumps(request["testSetSource"]),
            job_id,
            current_time
        ))

        conn.commit()
        conn.close()

        # Start evaluation job asynchronously
        asyncio.create_task(run_evaluation_job(evaluation_id, job_id))

        return {
            "id": evaluation_id,
            "name": request["name"],
            "scenario_type": request["scenario_type"],
            "status": "PENDING",
            "trained_model_id": request["trained_model_id"],
            "test_set_source": request["testSetSource"],
            "job_id": job_id,
            "created_at": current_time
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error creating evaluation run: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


# =============================================================================
# Training Data Statistics Collection
# =============================================================================

async def collect_training_data_statistics(experiment_run_id: str, data_source_config: dict, model_id: str):
    """收集訓練資料統計信息，按照前端期望的格式"""
    try:
        import sqlite3
        import json

        # 連接資料庫
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 獲取資料源配置
        positive_data_source_ids = data_source_config.get("positive_data_source_ids", [])
        unlabeled_data_source_ids = data_source_config.get("unlabeled_data_source_ids", [])
        split_ratios = data_source_config.get("split_ratios", {})
        training_sampling = data_source_config.get("training_sampling", {})

        # 初始化前端期望的資料結構
        training_data_stats = {
            "p_data_sources": {
                "dataset_ids": positive_data_source_ids,
                "dataset_info": {},
                "dataset_names": {},
                "total_samples": 0,
                "total_train_samples": 0,
                "total_validation_samples": 0,
                "total_test_samples": 0,
                "actual_train_samples": 0,
                "actual_validation_samples": 0,
                "actual_test_samples": 0
            },
            "u_data_sources": {
                "dataset_ids": unlabeled_data_source_ids,
                "dataset_info": {},
                "dataset_names": {},
                "total_samples": 0,
                "total_train_samples": 0,
                "total_validation_samples": 0,
                "total_test_samples": 0,
                "actual_train_samples": 0,
                "actual_validation_samples": 0,
                "actual_test_samples": 0
            },
            "data_split_ratios": {
                "train_ratio": split_ratios.get("train", 0.7),
                "validation_ratio": split_ratios.get("validation", 0.1),
                "test_ratio": split_ratios.get("test", 0.2)
            },
            "split_ratios": split_ratios,
            "overlap_removal": True,
            "u_sampling_applied": training_sampling.get("u_sample_ratio", 0.1) < 1.0,
            "total_samples": 0,
            "train_pool_size": 0,
            "validation_pool_size": 0,
            "test_pool_size": 0,
            "train_p_count": 0,
            "train_u_full_count": 0,
            "train_u_sampled_count": 0,
            "u_sample_ratio": training_sampling.get("u_sample_ratio", 0.1),
            "random_seed": training_sampling.get("random_seed", 0),
            "sampling_method": training_sampling.get("method", "static_subset"),
            "split_method": "time_based",
            "final_training_samples": 0,
            "actual_train_p_samples": 0,
            "actual_train_u_samples": 0
        }

        # 收集 P 資料統計
        total_positive_samples = 0
        if positive_data_source_ids:
            for dataset_id in positive_data_source_ids:
                cursor.execute('''
                    SELECT name, positive_labels, total_records FROM analysis_datasets WHERE id = ?
                ''', (dataset_id,))
                result = cursor.fetchone()
                if result:
                    dataset_name, positive_count, total_count = result
                    positive_count = positive_count or 0

                    # 計算分割
                    train_ratio = split_ratios.get("train", 0.7)
                    val_ratio = split_ratios.get("validation", 0.1)
                    test_ratio = split_ratios.get("test", 0.2)

                    train_samples = int(positive_count * train_ratio)
                    val_samples = int(positive_count * val_ratio)
                    test_samples = positive_count - train_samples - val_samples

                    training_data_stats["p_data_sources"]["dataset_info"][dataset_id] = {
                        "total_samples": positive_count,
                        "train_samples": train_samples,
                        "validation_samples": val_samples,
                        "test_samples": test_samples
                    }
                    training_data_stats["p_data_sources"]["dataset_names"][dataset_id] = dataset_name

                    training_data_stats["p_data_sources"]["total_samples"] += positive_count
                    training_data_stats["p_data_sources"]["total_train_samples"] += train_samples
                    training_data_stats["p_data_sources"]["total_validation_samples"] += val_samples
                    training_data_stats["p_data_sources"]["total_test_samples"] += test_samples

                    total_positive_samples += positive_count

        # 收集 U 資料統計
        total_unlabeled_samples = 0
        if unlabeled_data_source_ids:
            for dataset_id in unlabeled_data_source_ids:
                cursor.execute('''
                    SELECT name, total_records, positive_labels FROM analysis_datasets WHERE id = ?
                ''', (dataset_id,))
                result = cursor.fetchone()
                if result:
                    dataset_name, total_count, positive_count = result
                    unlabeled_count = (total_count or 0) - (positive_count or 0)  # U = Total - P

                    # 計算分割
                    train_ratio = split_ratios.get("train", 0.7)
                    val_ratio = split_ratios.get("validation", 0.1)
                    test_ratio = split_ratios.get("test", 0.2)

                    train_samples = int(unlabeled_count * train_ratio)
                    val_samples = int(unlabeled_count * val_ratio)
                    test_samples = unlabeled_count - train_samples - val_samples

                    training_data_stats["u_data_sources"]["dataset_info"][dataset_id] = {
                        "total_samples": unlabeled_count,
                        "train_samples": train_samples,
                        "validation_samples": val_samples,
                        "test_samples": test_samples
                    }
                    training_data_stats["u_data_sources"]["dataset_names"][dataset_id] = dataset_name

                    training_data_stats["u_data_sources"]["total_samples"] += unlabeled_count
                    training_data_stats["u_data_sources"]["total_train_samples"] += train_samples
                    training_data_stats["u_data_sources"]["total_validation_samples"] += val_samples
                    training_data_stats["u_data_sources"]["total_test_samples"] += test_samples

                    total_unlabeled_samples += unlabeled_count

        # 計算總體統計
        total_samples = total_positive_samples + total_unlabeled_samples
        training_data_stats["total_samples"] = total_samples

        # 計算資料池大小
        train_ratio = split_ratios.get("train", 0.7)
        val_ratio = split_ratios.get("validation", 0.1)
        test_ratio = split_ratios.get("test", 0.2)

        training_data_stats["train_pool_size"] = int(total_samples * train_ratio)
        training_data_stats["validation_pool_size"] = int(total_samples * val_ratio)
        training_data_stats["test_pool_size"] = total_samples - training_data_stats["train_pool_size"] - training_data_stats["validation_pool_size"]

        # 計算訓練集 P/U 樣本數
        train_p_samples = int(total_positive_samples * train_ratio)
        train_u_full = int(total_unlabeled_samples * train_ratio)

        # 應用 U 採樣
        u_sample_ratio = training_sampling.get("u_sample_ratio", 0.1)
        train_u_sampled = int(train_u_full * u_sample_ratio)

        training_data_stats["train_p_count"] = train_p_samples
        training_data_stats["train_u_full_count"] = train_u_full
        training_data_stats["train_u_sampled_count"] = train_u_sampled
        training_data_stats["final_training_samples"] = train_p_samples + train_u_sampled
        training_data_stats["actual_train_p_samples"] = train_p_samples
        training_data_stats["actual_train_u_samples"] = train_u_sampled

        # 更新 actual samples
        training_data_stats["p_data_sources"]["actual_train_samples"] = train_p_samples
        training_data_stats["u_data_sources"]["actual_train_samples"] = train_u_sampled

        conn.close()
        return training_data_stats

    except Exception as e:
        logger.error(f"Error collecting training data statistics: {str(e)}")
        return {}
# =============================================================================
# Training and Evaluation Job Runners
# =============================================================================

async def run_training_job(model_id: str, job_id: str):
    """🆕 Run training job using our enhanced F1-Score monitoring ModelTrainer"""
    try:
        import sqlite3
        import json

        logger.info(f"🚀 Starting F1-Score monitoring training job {job_id} for model {model_id}")

        # ✅ 立即發送第一條日誌，確保前端可以立即看到進度
        if websocket_manager:
            await websocket_manager.send_training_log(job_id, {
                "type": "status",
                "message": "🚀 Training job started! Initializing F1-Score monitoring environment..."
            })
            logger.info(f"📡 First training log sent for job: {job_id}")

        # 獲取模型配置和實驗信息
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 獲取模型配置
        cursor.execute('''
            SELECT name, scenario_type, experiment_run_id, model_config, data_source_config
            FROM trained_models
            WHERE id = ?
        ''', (model_id,))

        model_row = cursor.fetchone()
        if not model_row:
            raise Exception(f"Model {model_id} not found")

        model_name, scenario_type, experiment_run_id, model_config_str, data_source_config_str = model_row

        logger.info(f"🔍 Loading model configuration for F1 monitoring: {model_name}")
        logger.info(f"🔍 Model config type: {type(model_config_str)}")

        # 解析 JSON 配置
        try:
            if isinstance(model_config_str, str):
                model_config_dict = json.loads(model_config_str)
            else:
                model_config_dict = model_config_str
            logger.info(f"✅ Model config parsed successfully for F1 monitoring")
        except json.JSONDecodeError as e:
            logger.error(f"❌ Model config parse failed: {e}")
            model_config_dict = {}

        try:
            if isinstance(data_source_config_str, str):
                data_source_config_dict = json.loads(data_source_config_str)
            else:
                data_source_config_dict = data_source_config_str
            logger.info(f"✅ Data source config parsed successfully for F1 monitoring")
        except json.JSONDecodeError as e:
            logger.error(f"❌ Data source config parse failed: {e}")
            data_source_config_dict = {}

        # 🆕 使用我們的 ModelTrainer 和 F1-Score 監控功能
        global model_trainer
        if not model_trainer:
            raise Exception("ModelTrainer service not available")

        # 🆕 轉換配置為 ModelTrainer 所需的格式
        from services.case_study_v2.models import StartTrainingJobRequest, ModelConfig, DataSourceConfig, ScenarioType

        # 創建 ModelConfig 對象
        model_config = ModelConfig(
            modelType=model_config_dict.get("modelType", "nnPU"),
            epochs=int(model_config_dict.get("epochs", 100)),
            hiddenSize=int(model_config_dict.get("hiddenSize", 64)),
            numLayers=int(model_config_dict.get("numLayers", 3)),
            activationFunction=model_config_dict.get("activationFunction", "relu"),
            dropout=float(model_config_dict.get("dropout", 0.3)),
            windowSize=int(model_config_dict.get("windowSize", 10)),
            learningRate=float(model_config_dict.get("learningRate", 0.001)),
            batchSize=int(model_config_dict.get("batchSize", 32)),
            optimizer=model_config_dict.get("optimizer", "adam"),
            l2Regularization=float(model_config_dict.get("l2Regularization", 0.01)),
            earlyStopping=bool(model_config_dict.get("earlyStopping", True)),
            patience=int(model_config_dict.get("patience", 10)),
            learningRateScheduler=model_config_dict.get("learningRateScheduler", "StepLR"),
            classPrior=float(model_config_dict.get("classPrior", 0.3))
        )

        # 創建 DataSourceConfig 對象
        data_source_config = DataSourceConfig(
            trainRatio=float(data_source_config_dict.get("trainRatio", 70.0)),
            validationRatio=float(data_source_config_dict.get("validationRatio", 20.0)),
            testRatio=float(data_source_config_dict.get("testRatio", 10.0)),
            timeRange=data_source_config_dict.get("timeRange", {"startDate": "", "endDate": ""})
        )

        # 創建訓練請求對象
        training_request = StartTrainingJobRequest(
            model_name=model_name,
            scenario_type=ScenarioType(scenario_type),
            experiment_run_id=experiment_run_id,
            training_config=model_config,
            data_source_config=data_source_config
        )

        logger.info(f"🎯 Starting F1-Score monitoring training with ModelTrainer")
        logger.info(f"   - Model: {model_name}")
        logger.info(f"   - Epochs: {model_config.epochs}")
        logger.info(f"   - Early Stopping: {model_config.earlyStopping} (patience: {model_config.patience})")
        logger.info(f"   - F1-based monitoring: Enabled")

        # 🆕 收集訓練資料統計信息
        try:
            training_data_info = await collect_training_data_statistics(
                experiment_run_id=experiment_run_id,
                data_source_config=data_source_config_dict,
                model_id=model_id
            )
            logger.info(f"📊 Training data statistics collected successfully")
        except Exception as stats_error:
            logger.warning(f"⚠️ Failed to collect training data statistics: {stats_error}")
            training_data_info = {}

        # 🆕 調用我們的 ModelTrainer 進行 F1-Score 監控訓練
        await model_trainer.train_model(
            job_id=job_id,
            trained_model_id=model_id,
            config=training_request,
            training_data_info=training_data_info  # 傳遞訓練資料統計
        )
        logger.info(f"model_trainer.train_model end")


    # 🆕 訓練完成後，使用 SQL 直接更新 training_data_info
    # 這裡使用底層資料庫欄位名稱 training_data_info（下劃線）
    # 而透過 Prisma ORM 時需要使用 camelCase: trainingDataInfo
        if training_data_info:
            try:
                cursor.execute('''
                    UPDATE trained_models
                    SET training_data_info = ?
                    WHERE id = ?
                ''', (json.dumps(training_data_info), model_id))
                conn.commit()
                logger.info(f"✅ Training data statistics saved successfully for model {model_id}")
            except Exception as sql_error:
                logger.warning(f"⚠️ Failed to save training data statistics via SQL: {sql_error}")

        conn.close()

    except Exception as e:
        logger.error(f"❌ F1-Score monitoring training job {job_id} failed: {str(e)}")

        # Send error via WebSocket
        if websocket_manager:
            await websocket_manager.send_training_log(job_id, {
                "type": "error",
                "message": f"F1-Score monitoring training failed: {str(e)}"
            })

        # Update status to FAILED
        try:
            db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            cursor.execute('UPDATE trained_models SET status = ? WHERE id = ?', ("FAILED", model_id))
            conn.commit()
            conn.close()
        except:
            pass

async def run_evaluation_job(evaluation_id: str, job_id: str):
    """Run evaluation job using the CORRECT ModelEvaluator with shared models"""
    logger.info("ROUTER: V2 evaluation job endpoint triggered.")

    try:
        # Use the global model_evaluator that was properly initialized
        global model_evaluator, websocket_manager

        if not model_evaluator:
            logger.error("ModelEvaluator not initialized!")
            raise RuntimeError("ModelEvaluator service not available")

        # Set websocket manager for real-time logging
        if websocket_manager:
            model_evaluator.set_websocket_manager(websocket_manager)

        logger.info(f"🚀 Starting CORRECT (V2) evaluation job {job_id} for evaluation {evaluation_id}")

        # Get evaluation configuration from database
        import sqlite3
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # Update status to RUNNING
        cursor.execute('''
            UPDATE evaluation_runs
            SET status = ?
            WHERE id = ?
        ''', ("RUNNING", evaluation_id))
        conn.commit()

        # Get evaluation run details
        cursor.execute('''
            SELECT trained_model_id, test_set_source
            FROM evaluation_runs
            WHERE id = ?
        ''', (evaluation_id,))

        eval_row = cursor.fetchone()
        if not eval_row:
            raise Exception(f"Evaluation run {evaluation_id} not found")

        trained_model_id, test_set_source_str = eval_row

        # 🆕 獲取訓練模型的數據源配置，確保評估使用相同的數據來源
        cursor.execute('''
            SELECT data_source_config
            FROM trained_models
            WHERE id = ?
        ''', (trained_model_id,))

        model_row = cursor.fetchone()
        if not model_row:
            conn.close()
            raise Exception(f"Trained model {trained_model_id} not found")

        model_data_source_config_str = model_row[0]
        conn.close()  # 🆕 在這裡關閉資料庫連接

        # Parse test_set_source from JSON string to dict
        import json

        logger.info(f"🔍 Debug: Original test_set_source_str = {test_set_source_str}")
        logger.info(f"🔍 Debug: test_set_source_str type = {type(test_set_source_str)}")

        try:
            if isinstance(test_set_source_str, str):
                test_set_source = json.loads(test_set_source_str)
                logger.info(f"🔍 Debug: JSON parsing successful, parsed to dict")
            else:
                test_set_source = test_set_source_str
                logger.info(f"🔍 Debug: No parsing needed, already a dict")

            logger.info(f"🔍 Debug: Final test_set_source type = {type(test_set_source)}")
            logger.info(f"🔍 Debug: Final test_set_source = {test_set_source}")

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse test_set_source_str: {e}")
            logger.error(f"Raw test_set_source_str: {test_set_source_str}")
            raise Exception(f"Invalid test_set_source JSON: {e}")

        try:
            if isinstance(model_data_source_config_str, str):
                model_data_source_config = json.loads(model_data_source_config_str)
            else:
                model_data_source_config = model_data_source_config_str
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse model_data_source_config_str: {e}")
            logger.error(f"Raw model_data_source_config_str: {model_data_source_config_str}")
            # Set to empty dict as fallback
            model_data_source_config = {}

        # Validate that test_set_source is a dict
        if not isinstance(test_set_source, dict):
            logger.error(f"❌ CRITICAL: test_set_source is not a dict after parsing!")
            logger.error(f"   Type: {type(test_set_source)}")
            logger.error(f"   Value: {test_set_source}")
            logger.error(f"   Original string: {test_set_source_str}")
            # Try to force parse one more time
            try:
                # If the first parse resulted in a string, it might be double-encoded JSON.
                # So, we parse the *result* of the first parse.
                if isinstance(test_set_source, str):
                    test_set_source = json.loads(test_set_source)
                else:
                    # Fallback to parsing the original string again, just in case.
                    test_set_source = json.loads(test_set_source_str)
                logger.info(f"✅ Force parsing successful: {type(test_set_source)}")
            except Exception as force_error:
                logger.error(f"❌ Force parsing also failed: {force_error}")
                raise Exception(f"test_set_source must be a dictionary, got {type(test_set_source)}")
        else:
            logger.info(f"✅ test_set_source is correctly parsed as dict")

        # 🆕 Enhanced test_set_source with training data source information
        enhanced_test_set_source = {
            **test_set_source,
            # 從訓練模型配置中獲取數據源信息
            "positive_data_source_ids": model_data_source_config.get("positive_data_source_ids", []),
            "unlabeled_data_source_ids": model_data_source_config.get("unlabeled_data_source_ids", []),
            "source_dataset_ids": model_data_source_config.get("source_dataset_ids", []),
            "split_ratios": model_data_source_config.get("split_ratios", {}),
            "split_method": model_data_source_config.get("split_method", "time_based"),
            "training_sampling": model_data_source_config.get("training_sampling", {})
        }

        logger.info(f"🔍 Enhanced test_set_source with training data sources:")
        logger.info(f"   - Original: {test_set_source}")
        logger.info(f"   - Enhanced: {enhanced_test_set_source}")

        # Create a minimal config object for the evaluator
        # The evaluator will handle all the complex logic
        config_dict = {
            "evaluation_id": evaluation_id,
            "trained_model_id": trained_model_id,
            "test_set_source": enhanced_test_set_source  # 🆕 使用增強的測試集配置
        }

        # Import the StartEvaluationJobRequest model
        from services.case_study_v2.models import StartEvaluationJobRequest

        # Create a proper config object (the evaluator expects this type)
        class SimpleConfig:
            def __init__(self, data):
                self.evaluation_id = data["evaluation_id"]
                self.trained_model_id = data["trained_model_id"]
                self.test_set_source = data["test_set_source"]

        config = SimpleConfig(config_dict)

        # Call the CORRECT ModelEvaluator.evaluate_model method
        await model_evaluator.evaluate_model(job_id, evaluation_id, config)

        logger.info(f"✅ CORRECT (V2) evaluation job {job_id} completed successfully")

    except Exception as e:
        import traceback
        logger.error(f"❌ CORRECT (V2) evaluation job {job_id} failed: {str(e)}")
        logger.error(f"Full traceback: {traceback.format_exc()}")

        # Send error via WebSocket
        if websocket_manager:
            await websocket_manager.send_evaluation_log(job_id, {
                "type": "error",
                "message": f"Evaluation failed: {str(e)}"
            })

        # Update status to FAILED
        try:
            import sqlite3
            db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
            error_conn = sqlite3.connect(db_path)
            error_cursor = error_conn.cursor()
            error_cursor.execute('UPDATE evaluation_runs SET status = ? WHERE id = ?', ("FAILED", evaluation_id))
            error_conn.commit()
            error_conn.close()
        except Exception as update_error:
            logger.error(f"Failed to update evaluation status to FAILED: {update_error}")

# ========== Stage 3: nnPU Training API Routes ==========

@case_study_v2_router.get("/training-jobs")
async def get_training_jobs():
    """獲取所有訓練工作的狀態"""
    try:
        # 連接到資料庫
        import sqlite3
        db_path = '/home/infowin/Git-projects/pu-in-practice/backend/database/prisma/pu_practice.db'
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # 查詢訓練工作
        cursor.execute('''
            SELECT id, taskId, experimentId, status, startedAt, completedAt,
                   modelType, hyperparameters, dataSourceConfig, metrics, errorMessage,
                   createdAt, updatedAt
            FROM training_jobs
            ORDER BY createdAt DESC
        ''')

        jobs = []
        for row in cursor.fetchall():
            job = {
                "id": row[0],
                "taskId": row[1],
                "experimentId": row[2],
                "status": row[3],
                "startedAt": row[4],
                "completedAt": row[5],
                "modelType": row[6],
                "hyperparameters": json.loads(row[7]) if row[7] else {},
                "dataSourceConfig": json.loads(row[8]) if row[8] else {},
                "metrics": json.loads(row[9]) if row[9] else {},
                "errorMessage": row[10],
                "createdAt": row[11],
                "updatedAt": row[12]
            }
            jobs.append(job)

        conn.close()
        return jobs

    except Exception as e:
        logger.error(f"Error retrieving training jobs: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to retrieve training jobs: {str(e)}")


# ========== End of Stage 3 API Routes ==========
